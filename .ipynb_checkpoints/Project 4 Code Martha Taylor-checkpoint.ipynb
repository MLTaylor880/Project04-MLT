{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary predictor with Logistic Regression.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Question: Why would we want this to be a classification problem?\n",
    "- Answer: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9732c901-ae26-4160-8376-42e22dd327df"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "\n",
    "The URL here has many query parameters\n",
    "\n",
    "- `q` for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- `l` for a location \n",
    "- `start` for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e915023e-6b0d-4982-af2a-b1e0355f4927"
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2c6752c4-7704-4c94-8bc0-6f13d2d0d570"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "bb0b866a-26a7-45e9-8084-5a0f90eb4b3e"
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a `nobr` element inside of a `td` element with `class='snip`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element=\"jobTitle`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "f1eddb90-4ba8-483c-a229-77e93aa53119"
   },
   "source": [
    "### Write 4 functions to extract each item: location, company, job, and salary.\n",
    "\n",
    "example: \n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "\n",
    "- **Make sure these functions are robust and can handle cases where the data/field may not be available.**\n",
    "    - Remember to check if a field is empty or `None` for attempting to call methods on it\n",
    "    - Remember to use `try/except` if you anticipate errors\n",
    "- **Test** the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a1af53c9-9090-494f-b82e-cadb60a54909"
   },
   "source": [
    "I did different functions - ones that made sense to me.\n",
    "I check lenght of each list before I copy it to a backup.\n",
    "I had to run the code several times when I realized the lists did not match up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list to hold scraped data\n",
    "#the back up are used once it is determined that the list are the same length.\n",
    "#Twice I ended up with uneven list - this assures that I do not have to start from the top\n",
    "pd.set_option('max_colwidth',500)    # to remove column limit (Otherwise, we'll lose some info)\n",
    "df = pd.DataFrame()   # create a new data frame\n",
    "\n",
    "searchCriteria=[]\n",
    "salaryRange=[]\n",
    "jobTitle = []\n",
    "companyName=[]\n",
    "cityLocation=[]\n",
    "description=[]\n",
    "actualSalary=[]\n",
    "BackupsearchCriteria=[]\n",
    "BackupsalaryRange=[]\n",
    "BackupjobTitle = []\n",
    "BackupcompanyName=[]\n",
    "BackupcityLocation=[]\n",
    "Backupdescription=[]\n",
    "BackupactualSalary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function is to scrape the data off the first page of all cities. The Url is different for the \n",
    "#first page.\n",
    "#note I clean up the company name before I save it\n",
    "def extractDataFirstPage(priceRanges,city, level, b_URL):\n",
    "        time.sleep(1)   \n",
    "        base_url = b_URL\n",
    "        soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    \n",
    "        gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "        for item in gData:\n",
    "                searchCriteria.append('data scientist')\n",
    "                jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "                companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "                cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "                description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "                salaryRange.append(level) \n",
    "                \n",
    "\n",
    "        gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "        for item in gData:\n",
    "                searchCriteria.append('data scientist')\n",
    "                jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "                companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "                cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "                description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "                salaryRange.append(level)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To scape the data off pages 2 on\n",
    "def extractDataBeyondPages(priceRanges, city, level, b_URL, endPage,pVariableNu):\n",
    "        time.sleep(2) \n",
    "        pVariableNu=10\n",
    "        for pages in range(2,endPage): \n",
    "            pVariableNu=10+pVariableNu\n",
    "            pVariable=str(pVariableNu)\n",
    "            base_url = b_URL + pVariable\n",
    "            soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    \n",
    "            gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "            for item in gData:\n",
    "                searchCriteria.append('data scientist')\n",
    "                jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "                companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "                cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "                description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "                salaryRange.append(level)\n",
    "                #print base_url\n",
    "\n",
    "            gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "            for item in gData:\n",
    "                searchCriteria.append('data scientist')\n",
    "                jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "                companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "                cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "                description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "                salaryRange.append(level)\n",
    "                #print base_url\n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#backing up during the process because I am paranoid\n",
    "def backup_lists():\n",
    "    BackupsearchCriteria =searchCriteria \n",
    "    BackupsalaryRange=salaryRange\n",
    "    BackupjobTitle =jobTitle\n",
    "    BackupcompanyName=companyName\n",
    "    BackupcityLocation=cityLocation\n",
    "    Backupdescription=description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checking to make sure all are same length\n",
    "def print_lengths():\n",
    "    print len(searchCriteria)\n",
    "    print len(jobTitle)\n",
    "    print len(companyName)\n",
    "    print len(cityLocation)\n",
    "    print len(salaryRange)\n",
    "    print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "#Chicago all salaries page 1\n",
    "#large city good supply of jobs and applicants\n",
    "priceRanges = ['$55,000','$70,000','$85,000','$100,000','$120,000']\n",
    "for price in priceRanges:\n",
    "    if price == '$55,000':\n",
    "            level = 'low'\n",
    "            endPage=41\n",
    "    elif price == '$70,000':\n",
    "            level = 'low'\n",
    "            endPage=33\n",
    "    elif price == '$85,000':\n",
    "            level = 'low'\n",
    "            endPage=26\n",
    "    elif price == '$100,000':\n",
    "            level = 'high'\n",
    "            endPage=9\n",
    "    else:\n",
    "            level = 'high'\n",
    "            endPage=9\n",
    "    city = 'Chicago'\n",
    "    b_URL='http://www.indeed.com/q-data-scientist-'+ price +'-l-Chicago,-IL-jobs.html'\n",
    "    extractDataFirstPage(priceRanges, city,level,b_URL)\n",
    "print_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n"
     ]
    }
   ],
   "source": [
    "#Chicago  other pages\n",
    "priceRanges = ['$55,000','$70,000','$85,000','$100,000','$120,000']\n",
    "\n",
    "for price in priceRanges:\n",
    "    if price == '$55,000':\n",
    "            level = 'low'\n",
    "            endPage=41\n",
    "            salaryCode='55'\n",
    "    elif price == '$70,000':\n",
    "            level = 'low'\n",
    "            endPage=33\n",
    "            salaryCode='70'\n",
    "    elif price == '$85,000':\n",
    "            level = 'low'\n",
    "            endPage=26\n",
    "            salaryCode='85'\n",
    "    elif price == '$100,000':\n",
    "            level = 'high'\n",
    "            endPage=18\n",
    "            salaryCode='100'\n",
    "    else:\n",
    "            level = 'high'\n",
    "            endPage=9\n",
    "            salaryCode='120'\n",
    "    pVariableNu=10\n",
    "    city = 'Chicago'\n",
    "    b_URL='http://www.indeed.com/jobs?q=data+scientist+%24'+salaryCode+'%2C000&l=Chicago%2C+IL&start='\n",
    "    extractDataBeyondPages(price, city, level, b_URL, endPage, pVariableNu)\n",
    "\n",
    "print_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125\n",
      "1125\n",
      "1125\n",
      "1125\n",
      "1125\n",
      "1125\n"
     ]
    }
   ],
   "source": [
    "#Cincinnati all salaries page 1\n",
    "priceRanges = ['$50,000','$55,000','$65,000','$90,000','$110,000']\n",
    "for price in priceRanges:\n",
    "    if price == '$50,000':\n",
    "            level = 'low'\n",
    "            endPage=9\n",
    "    elif price == '$55,000':\n",
    "            level = 'low'\n",
    "            endPage=7\n",
    "    elif price == '$65,000':\n",
    "            level = 'low'\n",
    "            endPage=6\n",
    "    elif price == '$90,000':\n",
    "            level = 'low'\n",
    "            endPage=4\n",
    "    else:\n",
    "            level = 'high'\n",
    "            endPage=3\n",
    "    city = 'Cincinnati'\n",
    "    b_URL='http://www.indeed.com/q-data-scientist-'+ price +'-l-Cincinnati,-OH-jobs.html'\n",
    "    extractDataFirstPage(priceRanges, city,level,b_URL)\n",
    "print_lengths()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314\n",
      "1314\n",
      "1314\n",
      "1314\n",
      "1314\n",
      "1314\n"
     ]
    }
   ],
   "source": [
    "#Cincinnati  other pages\n",
    "priceRanges = ['$50,000','$55,000','$65,000','$90,000','$110,000']\n",
    "for price in priceRanges:\n",
    "    if price == '$50,000':\n",
    "            level = 'low'\n",
    "            endPage=9\n",
    "            salaryCode='50'\n",
    "    elif price == '$55,000':\n",
    "            level = 'low'\n",
    "            endPage=8\n",
    "            salaryCode='55'\n",
    "    elif price == '$65,000':\n",
    "            level = 'low'\n",
    "            endPage=6\n",
    "            salaryCode='65'\n",
    "    elif price == '$90,000':\n",
    "            level = 'low'\n",
    "            endPage=4\n",
    "            salaryCode='90'\n",
    "    else:\n",
    "            level = 'high'\n",
    "            endPage=3\n",
    "            salaryCode='110'\n",
    "\n",
    "    city = 'Cincinnati'\n",
    "    b_URL='http://www.indeed.com/jobs?q=data+scientist+%24'+salaryCode+'%2C000&l=Chicago%2C+IL&start='\n",
    "    pVariableNu=10\n",
    "    extractDataBeyondPages(price,city, level,b_URL,endPage,pVariableNu)\n",
    "print_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125\n",
      "1125\n",
      "1125\n",
      "1125\n",
      "1125\n",
      "1125\n"
     ]
    }
   ],
   "source": [
    "print_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1367\n",
      "1367\n",
      "1367\n",
      "1367\n",
      "1367\n",
      "1367\n"
     ]
    }
   ],
   "source": [
    "#Louisville all salaries page 1\n",
    "priceRanges = ['$40,000','$55,000','$70,000','$100,000','$120,000']\n",
    "for price in priceRanges:\n",
    "    if price == '$40,000':\n",
    "            level = 'low'\n",
    "            endPage=2\n",
    "    elif price == '$55,000':\n",
    "            level = 'low'\n",
    "            endPage=3\n",
    "    elif price == '$70,000':\n",
    "            level = 'low'\n",
    "            endPage=3\n",
    "    elif price == '$100,000':\n",
    "            level = 'high'\n",
    "            endPage=3\n",
    "    else:\n",
    "            level = 'high'\n",
    "            endPage=3\n",
    "    city = 'Louisville'\n",
    "    b_URL= 'http://www.indeed.com/q-data-scientist-'+price +'-l-Louisville,-KY-jobs.html'\n",
    "    extractDataFirstPage(priceRanges, city,level,b_URL)\n",
    "print_lengths()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433\n",
      "1433\n",
      "1433\n",
      "1433\n",
      "1433\n",
      "1433\n"
     ]
    }
   ],
   "source": [
    "#Louisville other pages\n",
    "priceRanges = ['$40,000','$55,000','$70,000','$100,000','$120,000']\n",
    "for price in priceRanges:\n",
    "    if price == '$40,000':\n",
    "            level = 'low'\n",
    "            endPage=3\n",
    "            salaryCode='40'\n",
    "    elif price == '$55,000':\n",
    "            level = 'low'\n",
    "            endPage=3\n",
    "            salaryCode='55'\n",
    "    elif price == '$70,000':\n",
    "            level = 'low'\n",
    "            endPage=3\n",
    "            salaryCode='70'\n",
    "\n",
    "    elif price == '$100,000':\n",
    "            level = 'high'\n",
    "            endPage=3\n",
    "            salaryCode='100'\n",
    "    else:\n",
    "            level = 'high'\n",
    "            endPage=3\n",
    "            salaryCode='120'\n",
    "    pVariableNu=10\n",
    "    city = 'Louisville'\n",
    "    b_URL='http://www.indeed.com/jobs?q=data+scientist+%24'+salaryCode+'%2C000&l=Louisville%2C+KY&start='\n",
    "    extractDataBeyondPages(price,city, level,b_URL,endPage,pVariableNu)\n",
    "print_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1493\n",
      "1493\n",
      "1493\n",
      "1493\n",
      "1493\n",
      "1493\n"
     ]
    }
   ],
   "source": [
    "#Austin TX all salaries page 1\n",
    "priceRanges = ['$50,000','$70,000','$85,000','$100,000','$115,000']\n",
    "for price in priceRanges:\n",
    "    if price == '$50,000':\n",
    "            level = 'low'\n",
    "            endPage=16\n",
    "    elif price == '$70,000':\n",
    "            level = 'low'\n",
    "            endPage=13\n",
    "    elif price == '$85,000':\n",
    "            level = 'low'\n",
    "            endPage=9\n",
    "    elif price == '$100,000':\n",
    "            level = 'high'\n",
    "            endPage=7\n",
    "    else:\n",
    "            level = 'high'\n",
    "            endPage=4\n",
    "    city = 'Austin'\n",
    "    b_URL ='http://www.indeed.com/q-data-scientist-'+ price +'-l-Austin,-TX-jobs.html'\n",
    "    extractDataFirstPage(priceRanges, city,level,b_URL)\n",
    "print_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1835\n",
      "1835\n",
      "1835\n",
      "1835\n",
      "1835\n",
      "1835\n"
     ]
    }
   ],
   "source": [
    "#Austin other pages\n",
    "priceRanges = ['$50,000','$70,000','$85,000','$100,000','$115,000']\n",
    "for price in priceRanges:\n",
    "    if price == '$50,000':\n",
    "            level = 'low'\n",
    "            endPage=16\n",
    "            salaryCode='50'\n",
    "    elif price == '$70,000':\n",
    "            level = 'low'\n",
    "            endPage=13\n",
    "            salaryCode=='70'\n",
    "    elif price == '$85,000':\n",
    "            level = 'low'\n",
    "            endPage=9\n",
    "            salaryCode='85'\n",
    "    elif price == '$100,000':\n",
    "            level = 'high'\n",
    "            endPage=7\n",
    "            salaryCode='100'\n",
    "    else:\n",
    "            level = 'high'\n",
    "            endPage=4\n",
    "            salaryCode='115'\n",
    "    pVariableNu=10\n",
    "    city = 'Austin'\n",
    "    b_URL='http://www.indeed.com/jobs?q=data+scientist+%24'+salaryCode+'%2C000&l=Austin%2C+TX&start='\n",
    "    extractDataBeyondPages(price,city, level,b_URL,endPage,pVariableNu)\n",
    "print_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1895\n",
      "1895\n",
      "1895\n",
      "1895\n",
      "1895\n",
      "1895\n"
     ]
    }
   ],
   "source": [
    "#San Franisco all salaries page 1\n",
    "priceRanges = ['$65,000','$85,000','$100,000','$115,000','$130,000']\n",
    "for price in priceRanges:\n",
    "    if price == '$65,000':\n",
    "            level = 'low'\n",
    "            endPage=168\n",
    "            salaryCode='65'\n",
    "    elif price == '$85,000':\n",
    "            level = 'low'\n",
    "            endPage=130\n",
    "            salaryCode='85'\n",
    "    elif price == '$100,000':\n",
    "            level = 'high'\n",
    "            endPage=100\n",
    "            salaryCode='100'\n",
    "    elif price == '$115,000':\n",
    "            level = 'high'\n",
    "            endPage=70\n",
    "            salaryCode='115'\n",
    "    else:\n",
    "            level = 'high'\n",
    "            endPage=35\n",
    "            salaryCode='130'\n",
    "    city = 'San Francisco'\n",
    "    b_URL ='http://www.indeed.com/q-data-scientist-'+ price +'-l-San-Francisco,-CA-jobs.html'\n",
    "    extractDataFirstPage(priceRanges, city,level,b_URL)\n",
    "print_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria2 =searchCriteria \n",
    "BackupsalaryRange2=salaryRange\n",
    "BackupjobTitle2 =jobTitle\n",
    "BackupcompanyName2=companyName\n",
    "BackupcityLocation2=cityLocation\n",
    "Backupdescription2=description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6297\n",
      "6297\n",
      "6297\n",
      "6297\n",
      "6297\n",
      "6297\n"
     ]
    }
   ],
   "source": [
    "#San Francisco other pages\n",
    "priceRanges = ['$65,000','$85,000','$100,000','$115,000','$130,000']\n",
    "for price in priceRanges:\n",
    "    if price == '$65,000':\n",
    "            level = 'low'\n",
    "            endPage=168\n",
    "            salaryCode='65'\n",
    "    elif price == '$85,000':\n",
    "            level = 'low'\n",
    "            endPage=130\n",
    "            salaryCode='85'\n",
    "    elif price == '$100,000':\n",
    "            level = 'high'\n",
    "            endPage=100\n",
    "            salaryCode='100'\n",
    "    elif price == '$115,000':\n",
    "            level = 'high'\n",
    "            endPage=70\n",
    "            salaryCode='115'\n",
    "    else:\n",
    "            level = 'high'\n",
    "            endPage=35\n",
    "            salaryCode='130'\n",
    "    city = 'San Francisco'\n",
    "    pVariableNu=10\n",
    "    b_URL='http://www.indeed.com/jobs?q=data+scientist+%24'+salaryCode+'%2C000&l=San+Francisco%2C+CA&start='\n",
    "    extractDataBeyondPages(price,city, level,b_URL,endPage,pVariableNu)\n",
    "print_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34070e89-9521-4b45-90c8-57a6599aac68"
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "e8beed7c-3e42-40c0-810f-5f67f8f885a0"
   },
   "source": [
    "#### Complete the following code to collect results from multiple cities and starting points. \n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a9aa87ec-3575-4a01-a986-eb684f2c47d0"
   },
   "outputs": [],
   "source": [
    "#see above: Chicago, Cincinnati, Louisville, Autin, and San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "04b0f9af-540e-402f-8292-81748707c676"
   },
   "outputs": [],
   "source": [
    "# url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "# max_results_per_city = 100 # Set this to a high-value (5000) to generate more results. \n",
    "# # Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "\n",
    "# results = []\n",
    "\n",
    "# for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "#     'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "#     'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY]):\n",
    "#     for start in range(0, max_results_per_city, 10):\n",
    "#         # Grab the results from the request (as above)\n",
    "#         # Append to the full set of results\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6297, 6)\n",
      "(2934, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: the take_last=True keyword is deprecated, use keep='last' instead\n"
     ]
    }
   ],
   "source": [
    "#merging the list together\n",
    "dictPostings={'Search Criteria':searchCriteria,\n",
    "              'Job Title':jobTitle,\n",
    "              'Company Name':companyName,\n",
    "              'City Location':cityLocation,\n",
    "              'Salary Level': salaryRange, \n",
    "              'Description':description}\n",
    "\n",
    "searchListings = pd.DataFrame(dictPostings)\n",
    "print searchListings.shape\n",
    "searchListings=searchListings.drop_duplicates(take_last=True)\n",
    "print searchListings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [],
   "source": [
    "## I did ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'City Location', u'Company Name', u'Description', u'Job Title',\n",
       "       u'Salary Level', u'Search Criteria'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##the get dummies\n",
    "searchListings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Level</th>\n",
       "      <th>Search Criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago, IL 60606</td>\n",
       "      <td>Purohit Navigation</td>\n",
       "      <td>Assist with data QC process on an ad hoc basis. We offer thoughtful research design, expertly executed data collection, and actionable research insights to...</td>\n",
       "      <td>Market Research Analyst</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>C R Research Services</td>\n",
       "      <td>\\nParticipate in the development of final written reports that involve presentation set-up and data posting. Coordinate all aspects of primary research projects...</td>\n",
       "      <td>Quantitative Research Analyst</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City Location           Company Name  \\\n",
       "2  Chicago, IL 60606     Purohit Navigation   \n",
       "8        Chicago, IL  C R Research Services   \n",
       "\n",
       "                                                                                                                                                           Description  \\\n",
       "2       Assist with data QC process on an ad hoc basis. We offer thoughtful research design, expertly executed data collection, and actionable research insights to...   \n",
       "8  \\nParticipate in the development of final written reports that involve presentation set-up and data posting. Coordinate all aspects of primary research projects...   \n",
       "\n",
       "                       Job Title Salary Level Search Criteria  \n",
       "2        Market Research Analyst          low  data scientist  \n",
       "8  Quantitative Research Analyst          low  data scientist  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating dummies for salary listings\n",
    "salaryDummies = pd.get_dummies(searchListings['Salary Level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    high  low\n",
       "2    0.0  1.0\n",
       "8    0.0  1.0\n",
       "9    0.0  1.0\n",
       "10   0.0  1.0\n",
       "12   0.0  1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaryDummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'high', u'low'], dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaryDummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the dummies for states\n",
    "#first the city state and zip need to be separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchListings=pd.concat([searchListings, \n",
    "                          searchListings['City Location'].str.split(',',expand=True)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchListings.columns=['City Location','Company Name',\n",
    "                       'Description','Job Title','Salary Level','Search Criteria',\n",
    "                       'City', 'State Zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchListings=pd.concat([searchListings, \n",
    "                          searchListings['State Zip'].str.split(' ',2,expand=True)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchListings.columns=['City Location','Company Name',\n",
    "                       'Description','Job Title','Salary Level','Search Criteria',\n",
    "                       'City','State Zip', 'blank','State','Zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA</th>\n",
       "      <th>IL</th>\n",
       "      <th>IN</th>\n",
       "      <th>KY</th>\n",
       "      <th>OH</th>\n",
       "      <th>TX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CA   IL   IN   KY   OH   TX\n",
       "2   0.0  1.0  0.0  0.0  0.0  0.0\n",
       "8   0.0  1.0  0.0  0.0  0.0  0.0\n",
       "9   0.0  1.0  0.0  0.0  0.0  0.0\n",
       "10  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "12  0.0  1.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#created dummies by state so not to get all the suburbs\n",
    "stateDummies=pd.get_dummies(searchListings['State'])\n",
    "stateDummies.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge in salary dummies\n",
    "searchListings=pd.concat([searchListings, salaryDummies],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge in state dummies\n",
    "searchListings=pd.concat([searchListings, stateDummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Level</th>\n",
       "      <th>Search Criteria</th>\n",
       "      <th>City</th>\n",
       "      <th>State Zip</th>\n",
       "      <th>blank</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>CA</th>\n",
       "      <th>IL</th>\n",
       "      <th>IN</th>\n",
       "      <th>KY</th>\n",
       "      <th>OH</th>\n",
       "      <th>TX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago, IL 60606</td>\n",
       "      <td>Purohit Navigation</td>\n",
       "      <td>Assist with data QC process on an ad hoc basis. We offer thoughtful research design, expertly executed data collection, and actionable research insights to...</td>\n",
       "      <td>Market Research Analyst</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60606</td>\n",
       "      <td></td>\n",
       "      <td>IL</td>\n",
       "      <td>60606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>C R Research Services</td>\n",
       "      <td>\\nParticipate in the development of final written reports that involve presentation set-up and data posting. Coordinate all aspects of primary research projects...</td>\n",
       "      <td>Quantitative Research Analyst</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td></td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Google</td>\n",
       "      <td>\\nExperience interpreting technical data and creating reports with data. Experience with data analytics and/or data visualization techniques and software....</td>\n",
       "      <td>Machine Learning Deployment Engineer, Professional Services,...</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td></td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Northwestern University</td>\n",
       "      <td>\\nEnsures data integrity. This includes database administration, data consolidation, data analysis and management reporting....</td>\n",
       "      <td>Statistical Analyst</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td></td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Precima</td>\n",
       "      <td>The Data Scientist will provide process execution support for client projects. Take analytical objectives and define data requirements....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td></td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City Location             Company Name  \\\n",
       "2   Chicago, IL 60606       Purohit Navigation   \n",
       "8         Chicago, IL    C R Research Services   \n",
       "9         Chicago, IL                   Google   \n",
       "10        Chicago, IL  Northwestern University   \n",
       "12        Chicago, IL                  Precima   \n",
       "\n",
       "                                                                                                                                                            Description  \\\n",
       "2        Assist with data QC process on an ad hoc basis. We offer thoughtful research design, expertly executed data collection, and actionable research insights to...   \n",
       "8   \\nParticipate in the development of final written reports that involve presentation set-up and data posting. Coordinate all aspects of primary research projects...   \n",
       "9         \\nExperience interpreting technical data and creating reports with data. Experience with data analytics and/or data visualization techniques and software....   \n",
       "10                                      \\nEnsures data integrity. This includes database administration, data consolidation, data analysis and management reporting....   \n",
       "12                           The Data Scientist will provide process execution support for client projects. Take analytical objectives and define data requirements....   \n",
       "\n",
       "                                                          Job Title  \\\n",
       "2                                           Market Research Analyst   \n",
       "8                                     Quantitative Research Analyst   \n",
       "9   Machine Learning Deployment Engineer, Professional Services,...   \n",
       "10                                              Statistical Analyst   \n",
       "12                                                   Data Scientist   \n",
       "\n",
       "   Salary Level Search Criteria     City  State Zip blank State    Zip  high  \\\n",
       "2           low  data scientist  Chicago   IL 60606          IL  60606   0.0   \n",
       "8           low  data scientist  Chicago         IL          IL   None   0.0   \n",
       "9           low  data scientist  Chicago         IL          IL   None   0.0   \n",
       "10          low  data scientist  Chicago         IL          IL   None   0.0   \n",
       "12          low  data scientist  Chicago         IL          IL   None   0.0   \n",
       "\n",
       "    low   CA   IL   IN   KY   OH   TX  \n",
       "2   1.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "8   1.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "9   1.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "10  1.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "12  1.0  0.0  1.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the next step I am going to separate the City State Zipcode.\n",
    "Since my cities are in separate states, below I will see if there is a relationship between location and salary level.  One would assume that there would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2934, 19)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1756.0\n",
      "1178.0\n"
     ]
    }
   ],
   "source": [
    "#basic exploratory stats\n",
    "#pd.pivot_table(salaryListings[salaryListings[]])\n",
    "print np.sum(searchListings['low'])\n",
    "print np.sum(searchListings['high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KY</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sum\n",
       "        high\n",
       "State       \n",
       "CA     935.0\n",
       "IL     156.0\n",
       "IN       1.0\n",
       "KY       4.0\n",
       "OH       9.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highPivot=pd.pivot_table(searchListings, \n",
    "                    index = ['State',], \n",
    "                        values=['high'], \n",
    "                        aggfunc = [np.sum]).head()\n",
    "lowPivot=pd.pivot_table(searchListings, \n",
    "                    index = ['State',], \n",
    "                        values=['low'], \n",
    "                        aggfunc = [np.sum]).head()\n",
    "highPivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KY</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sum\n",
       "          low\n",
       "State        \n",
       "CA     1195.0\n",
       "IL      394.0\n",
       "IN        1.0\n",
       "KY       11.0\n",
       "OH       14.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowPivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>1195.0</td>\n",
       "      <td>935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>394.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KY</th>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sum       \n",
       "          low   high\n",
       "State               \n",
       "CA     1195.0  935.0\n",
       "IL      394.0  156.0\n",
       "IN        1.0    1.0\n",
       "KY       11.0    4.0\n",
       "OH       14.0    9.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#salaryByState=pd.DataFrame(lowPivot).join(pd.DataFrame(highPivot))\n",
    "salaryByState=pd.concat([lowPivot, highPivot],axis=1)\n",
    "salaryByState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum low</th>\n",
       "      <th>sum high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>1195.0</td>\n",
       "      <td>935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>394.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KY</th>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sum low  sum high\n",
       "State                   \n",
       "CA      1195.0     935.0\n",
       "IL       394.0     156.0\n",
       "IN         1.0       1.0\n",
       "KY        11.0       4.0\n",
       "OH        14.0       9.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum of low salaries and sum of high salaries\n",
    "salaryByState.columns=[' '.join(col).strip() for col in salaryByState.columns.values]\n",
    "salaryByState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "searchListings.to_csv('SearchListings.csv', encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "source": [
    "The assumption that location will predict whether a salary will be high or low.  If it proves otherwise then I will look into whether words in the title predict high or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I started looking at predictors by feeding the states into a model\n",
    "I felt this would make a difference California does predict high but only with .59 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.056335</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.118462</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.441841</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619164</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Coefficient Feature\n",
       "3    -0.056335      CA\n",
       "1     0.118462      OH\n",
       "2     0.441841      TX\n",
       "0     0.619164      IL"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def examine_coefficients(model, df):\n",
    "    df = pd.DataFrame(\n",
    "        { 'Coefficient' : model.coef_[0] , 'Feature' : df.columns}\n",
    "    ).sort_values(by='Coefficient')\n",
    "    return df[df.Coefficient !=0 ]\n",
    "X=searchListings[['IL','OH','TX','CA']]\n",
    "y=searchListings['low']\n",
    "model = LogisticRegression() \n",
    "\n",
    "model.fit(X, y) # This fits the model to learn the coefficients\n",
    "examine_coefficients(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.598500340832\n"
     ]
    }
   ],
   "source": [
    "print model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.619164</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.441841</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.118462</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056335</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Coefficient Feature\n",
       "0    -0.619164      IL\n",
       "2    -0.441841      TX\n",
       "1    -0.118462      OH\n",
       "3     0.056335      CA"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def examine_coefficients(model, df):\n",
    "    df = pd.DataFrame(\n",
    "        { 'Coefficient' : model.coef_[0] , 'Feature' : df.columns}\n",
    "    ).sort_values(by='Coefficient')\n",
    "    return df[df.Coefficient !=0 ]\n",
    "X=searchListings[['IL','OH','TX', 'CA']]\n",
    "y=searchListings['high']\n",
    "model = LogisticRegression() \n",
    "\n",
    "model.fit(X, y) # This fits the model to learn the coefficients\n",
    "examine_coefficients(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.598500340832\n"
     ]
    }
   ],
   "source": [
    "print model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############  Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paramerters={\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':[0.1,1,10,23.5,50]}\n",
    "\n",
    "modelAmTesting=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=modelAmTesting, param_grid=paramerters,verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.598570 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.598160 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.598772 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.598570 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.598160 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.598772 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.598570 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.598160 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.598772 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.598570 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.598160 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.598772 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.598570 -   0.1s\n",
      "[CV] penalty=l1, C=10 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... penalty=l1, C=10, score=0.598160 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.598772 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.598570 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.598160 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.598772 -   0.0s\n",
      "[CV] penalty=l1, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l1, C=23.5, score=0.598570 -   0.1s\n",
      "[CV] penalty=l1, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l1, C=23.5, score=0.598160 -   0.0s\n",
      "[CV] penalty=l1, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l1, C=23.5, score=0.598772 -   0.0s\n",
      "[CV] penalty=l2, C=23.5 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... penalty=l2, C=23.5, score=0.598570 -   0.0s\n",
      "[CV] penalty=l2, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l2, C=23.5, score=0.598160 -   0.0s\n",
      "[CV] penalty=l2, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l2, C=23.5, score=0.598772 -   0.0s\n",
      "[CV] penalty=l1, C=50 ................................................\n",
      "[CV] ....................... penalty=l1, C=50, score=0.598570 -   0.2s\n",
      "[CV] penalty=l1, C=50 ................................................\n",
      "[CV] ....................... penalty=l1, C=50, score=0.598160 -   0.0s\n",
      "[CV] penalty=l1, C=50 ................................................\n",
      "[CV] ....................... penalty=l1, C=50, score=0.598772 -   0.0s\n",
      "[CV] penalty=l2, C=50 ................................................\n",
      "[CV] ....................... penalty=l2, C=50, score=0.598570 -   0.0s\n",
      "[CV] penalty=l2, C=50 ................................................\n",
      "[CV] ....................... penalty=l2, C=50, score=0.598160 -   0.0s\n",
      "[CV] penalty=l2, C=50 ................................................\n",
      "[CV] ....................... penalty=l2, C=50, score=0.598772 -   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 23.5, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.598500340832\n"
     ]
    }
   ],
   "source": [
    "print grid_search.best_score_\n",
    "#accuracy percent that the data set we fed into that it predicted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=grid_search.best_estimator_.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the confusion matrix\n",
    "The model predicted 1756 highs and their were high (True positive)\n",
    "The model predicted 1178 lows that were actually highs\n",
    "The accuracy is good at 75%  1756/(1178+0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1756,    0],\n",
       "       [1178,    0]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see heat map below \n",
    "\n",
    "confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      1.00      0.75      1756\n",
      "        1.0       0.00      0.00      0.00      1178\n",
      "\n",
      "avg / total       0.36      0.60      0.45      2934\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print classification_report(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118872290>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAD9CAYAAABp2RZmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYBhLUgoYxpKUAv8PY+Pe7NahU6EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1188728d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.heatmap(confusion_matrix(y,predictions),annot=True)\n",
    "\n",
    "#5.3e+02the true positive is 5300 Predicted low, and actual is low\n",
    "#2.6+02 is predicted it will be low but it acually is not now - false positive\n",
    "#0 for predicted not low and acually low\n",
    "#0 for predicted not low and it is not low\n",
    "#if these numbers are correct\n",
    "#0/(0+2700)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################  ridge model\n",
    "from sklearn.linear_model import Ridge\n",
    "#using ridge- l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare a Range of Alpha Values to Test\n",
    "alphas = np.array([100,10,1,0.1,0.01,0.001,0.0001,0])\n",
    "\n",
    "alphas\n",
    "model = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([  1.00000e+02,   1.00000e+01,   1.00000e+00,   1.00000e-01,\n",
      "         1.00000e-02,   1.00000e-03,   1.00000e-04,   0.00000e+00])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid={'alpha': alphas,})\n",
    "#a dictionary for param_grid  feed the dictionary to alpha\n",
    "grid.fit(X,y)\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.02352480178\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "#Summarize the Results of the Grid Search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016516509140380831"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model=grid.best_estimator_\n",
    "best_model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso\n",
    "logistic_model_1=LogisticRegression(penalty='l2')\n",
    "logistic_model_1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59850034083162917"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model_1.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model_2=LogisticRegression(penalty='l1', C=0.1)\n",
    "logistic_model_2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59850034083162917"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model_2.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "logistic_model_1=LogisticRegression(penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model_1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59850034083162917"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model_1.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_model_2=LogisticRegression(penalty='l2', C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model_2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6070211315610089"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model_2.score(X,y)\n",
    "#smaller values= more regulation\n",
    "#higher  getting rid of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't have to choice the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "source": [
    "I couldn't calculate the median salary since I did not pull the actual salary data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Logistic Regression model to predict High/Low salary using statsmodel. Start by ONLY using the location as a feature. Display the coefficients and write a short summary of what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title \n",
    "- or whether 'Manager' is in the title. \n",
    "- Then build a new Logistic Regression model with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [],
   "source": [
    "#focus on words - perhaps they do a better job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "v = CountVectorizer(\n",
    "    binary=True,  # Create binary features\n",
    "    stop_words='english', # Ignore common words such as 'the', 'and'\n",
    "    max_features=30, # Only use the top 50 most common words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyst</th>\n",
       "      <th>analytics</th>\n",
       "      <th>architect</th>\n",
       "      <th>associate</th>\n",
       "      <th>big</th>\n",
       "      <th>bioinformatics</th>\n",
       "      <th>business</th>\n",
       "      <th>clinical</th>\n",
       "      <th>data</th>\n",
       "      <th>developer</th>\n",
       "      <th>development</th>\n",
       "      <th>director</th>\n",
       "      <th>engineer</th>\n",
       "      <th>engineering</th>\n",
       "      <th>lead</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>manager</th>\n",
       "      <th>platform</th>\n",
       "      <th>principal</th>\n",
       "      <th>product</th>\n",
       "      <th>quantitative</th>\n",
       "      <th>research</th>\n",
       "      <th>science</th>\n",
       "      <th>scientist</th>\n",
       "      <th>senior</th>\n",
       "      <th>software</th>\n",
       "      <th>sr</th>\n",
       "      <th>staff</th>\n",
       "      <th>statistical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analyst  analytics  architect  associate  big  bioinformatics  business  \\\n",
       "0        1          0          0          0    0               0         0   \n",
       "1        1          0          0          0    0               0         0   \n",
       "2        0          0          0          0    0               0         0   \n",
       "3        1          0          0          0    0               0         0   \n",
       "4        0          0          0          0    0               0         0   \n",
       "\n",
       "   clinical  data  developer  development  director  engineer  engineering  \\\n",
       "0         0     0          0            0         0         0            0   \n",
       "1         0     0          0            0         0         0            0   \n",
       "2         0     0          0            0         0         1            0   \n",
       "3         0     0          0            0         0         0            0   \n",
       "4         0     1          0            0         0         0            0   \n",
       "\n",
       "   lead  learning  machine  manager  platform  principal  product  \\\n",
       "0     0         0        0        0         0          0        0   \n",
       "1     0         0        0        0         0          0        0   \n",
       "2     0         1        1        0         0          0        0   \n",
       "3     0         0        0        0         0          0        0   \n",
       "4     0         0        0        0         0          0        0   \n",
       "\n",
       "   quantitative  research  science  scientist  senior  software  sr  staff  \\\n",
       "0             0         1        0          0       0         0   0      0   \n",
       "1             1         1        0          0       0         0   0      0   \n",
       "2             0         0        0          0       0         0   0      0   \n",
       "3             0         0        0          0       0         0   0      0   \n",
       "4             0         0        0          1       0         0   0      0   \n",
       "\n",
       "   statistical  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This builds a matrix with a row per website (or data point) and column per word (using all words in the dataset)\n",
    "wordsJobTitle = v.fit_transform(searchListings['Job Title']).todense()     #no difference between data.title and data['title]\n",
    "wordsJobTitle = pd.DataFrame(wordsJobTitle, columns=v.get_feature_names())\n",
    "wordsJobTitle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientist         1055\n",
      "data              1015\n",
      "engineer           647\n",
      "senior             603\n",
      "manager            349\n",
      "software           310\n",
      "analyst            233\n",
      "research           231\n",
      "sr                 217\n",
      "learning           200\n",
      "machine            197\n",
      "product            157\n",
      "director           146\n",
      "analytics          136\n",
      "science            114\n",
      "lead               108\n",
      "associate           96\n",
      "developer           86\n",
      "development         85\n",
      "statistical         81\n",
      "engineering         77\n",
      "principal           76\n",
      "quantitative        67\n",
      "staff               64\n",
      "clinical            50\n",
      "business            50\n",
      "big                 47\n",
      "platform            46\n",
      "bioinformatics      46\n",
      "architect           46\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print wordsJobTitle.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "listingsJobTitle=pd.DataFrame(searchListings).join(pd.DataFrame(wordsJobTitle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Level</th>\n",
       "      <th>Search Criteria</th>\n",
       "      <th>City</th>\n",
       "      <th>State Zip</th>\n",
       "      <th>blank</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>CA</th>\n",
       "      <th>IL</th>\n",
       "      <th>IN</th>\n",
       "      <th>KY</th>\n",
       "      <th>OH</th>\n",
       "      <th>TX</th>\n",
       "      <th>analyst</th>\n",
       "      <th>analytics</th>\n",
       "      <th>architect</th>\n",
       "      <th>associate</th>\n",
       "      <th>big</th>\n",
       "      <th>bioinformatics</th>\n",
       "      <th>business</th>\n",
       "      <th>clinical</th>\n",
       "      <th>data</th>\n",
       "      <th>developer</th>\n",
       "      <th>development</th>\n",
       "      <th>director</th>\n",
       "      <th>engineer</th>\n",
       "      <th>engineering</th>\n",
       "      <th>lead</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>manager</th>\n",
       "      <th>platform</th>\n",
       "      <th>principal</th>\n",
       "      <th>product</th>\n",
       "      <th>quantitative</th>\n",
       "      <th>research</th>\n",
       "      <th>science</th>\n",
       "      <th>scientist</th>\n",
       "      <th>senior</th>\n",
       "      <th>software</th>\n",
       "      <th>sr</th>\n",
       "      <th>staff</th>\n",
       "      <th>statistical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago, IL 60606</td>\n",
       "      <td>Purohit Navigation</td>\n",
       "      <td>Assist with data QC process on an ad hoc basis. We offer thoughtful research design, expertly executed data collection, and actionable research insights to...</td>\n",
       "      <td>Market Research Analyst</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60606</td>\n",
       "      <td></td>\n",
       "      <td>IL</td>\n",
       "      <td>60606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City Location        Company Name  \\\n",
       "2  Chicago, IL 60606  Purohit Navigation   \n",
       "\n",
       "                                                                                                                                                      Description  \\\n",
       "2  Assist with data QC process on an ad hoc basis. We offer thoughtful research design, expertly executed data collection, and actionable research insights to...   \n",
       "\n",
       "                 Job Title Salary Level Search Criteria     City  State Zip  \\\n",
       "2  Market Research Analyst          low  data scientist  Chicago   IL 60606   \n",
       "\n",
       "  blank State    Zip  high  low   CA   IL   IN   KY   OH   TX  analyst  \\\n",
       "2          IL  60606   0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0      0.0   \n",
       "\n",
       "   analytics  architect  associate  big  bioinformatics  business  clinical  \\\n",
       "2        0.0        0.0        0.0  0.0             0.0       0.0       0.0   \n",
       "\n",
       "   data  developer  development  director  engineer  engineering  lead  \\\n",
       "2   0.0        0.0          0.0       0.0       1.0          0.0   0.0   \n",
       "\n",
       "   learning  machine  manager  platform  principal  product  quantitative  \\\n",
       "2       1.0      1.0      0.0       0.0        0.0      0.0           0.0   \n",
       "\n",
       "   research  science  scientist  senior  software   sr  staff  statistical  \n",
       "2       0.0      0.0        0.0     0.0       0.0  0.0    0.0          0.0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listingsJobTitle.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'analyst', u'analytics', u'architect', u'associate', u'big',\n",
       "       u'bioinformatics', u'business', u'clinical', u'data', u'developer',\n",
       "       u'development', u'director', u'engineer', u'engineering', u'lead',\n",
       "       u'learning', u'machine', u'manager', u'platform', u'principal',\n",
       "       u'product', u'quantitative', u'research', u'science', u'scientist',\n",
       "       u'senior', u'software', u'sr', u'staff', u'statistical'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsJobTitle.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def examine_coefficients(model, df):\n",
    "    df = pd.DataFrame(\n",
    "        { 'Coefficient' : model.coef_[0] , 'Feature' : df.columns}\n",
    "    ).sort_values(by='Coefficient')\n",
    "    return df[df.Coefficient !=0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=listingsJobTitle['high']\n",
    "X=wordsJobTitle[['lead','senior','director']]\n",
    "#X=wordsJobTitle[['director']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.326278</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.451096</td>\n",
       "      <td>lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815006</td>\n",
       "      <td>director</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Coefficient   Feature\n",
       "1     0.326278    senior\n",
       "0     0.451096      lead\n",
       "2     0.815006  director"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression() \n",
    "\n",
    "model.fit(X, y) # This fits the model to learn the coefficients\n",
    "examine_coefficients(model, X)\n",
    "#wow now we are talking numbers lets do a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X=wordsJobTitle[['lead','senior','director']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.593463 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.600204 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.598772 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.593463 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.605317 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.607984 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.593463 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.605317 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.606960 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.593463 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.605317 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.622313 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.593463 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.602249 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.622313 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.593463 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.602249 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.622313 -   0.0s\n",
      "[CV] penalty=l1, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l1, C=23.5, score=0.593463 -   0.0s\n",
      "[CV] penalty=l1, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l1, C=23.5, score=0.602249 -   0.0s\n",
      "[CV] penalty=l1, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l1, C=23.5, score=0.622313 -   0.0s\n",
      "[CV] penalty=l2, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l2, C=23.5, score=0.593463 -   0.0s\n",
      "[CV] penalty=l2, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l2, C=23.5, score=0.602249 -   0.0s\n",
      "[CV] penalty=l2, C=23.5 ..............................................\n",
      "[CV] ..................... penalty=l2, C=23.5, score=0.622313 -   0.0s\n",
      "[CV] penalty=l1, C=50 ................................................\n",
      "[CV] ....................... penalty=l1, C=50, score=0.593463 -   0.0s\n",
      "[CV] penalty=l1, C=50 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... penalty=l1, C=50, score=0.602249 -   0.0s\n",
      "[CV] penalty=l1, C=50 ................................................\n",
      "[CV] ....................... penalty=l1, C=50, score=0.622313 -   0.0s\n",
      "[CV] penalty=l2, C=50 ................................................\n",
      "[CV] ....................... penalty=l2, C=50, score=0.593463 -   0.0s\n",
      "[CV] penalty=l2, C=50 ................................................\n",
      "[CV] ....................... penalty=l2, C=50, score=0.602249 -   0.0s\n",
      "[CV] penalty=l2, C=50 ................................................\n",
      "[CV] ....................... penalty=l2, C=50, score=0.622313 -   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 23.5, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramerters={\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':[0.1,1,10,23.5,50]}\n",
    "\n",
    "modelAmTesting=LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator=modelAmTesting, param_grid=paramerters, verbose=10)\n",
    "grid_search\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607021131561\n"
     ]
    }
   ],
   "source": [
    "print grid_search.best_score_\n",
    "#accuracy - ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=grid_search.best_estimator_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1692,   64],\n",
       "       [1089,   89]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.96      0.75      1756\n",
      "        1.0       0.58      0.08      0.13      1178\n",
      "\n",
      "avg / total       0.60      0.61      0.50      2934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print classification_report(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x125052c90>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAFRCAYAAADuAQ3SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwIFgBADAgWAEAMDh/wAWo9z4tX+CVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12504ac10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.heatmap(confusion_matrix(y,predictions),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9c9274ef-c9f5-4d56-b286-ecc8709eff9f"
   },
   "source": [
    "#### Rebuild this model with scikit-learn.\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy, AUC, precision and recall of the model. \n",
    "- Discuss the differences and explain when you want a high-recall or a high-precision model in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "8c22664b-92e4-4fc2-b7ac-fbac865845d3"
   },
   "source": [
    "#### Compare L1 and L2 regularization for this logistic regression model. What effect does this have on the coefficients learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([  1.00000e+02,   1.00000e+01,   1.00000e+00,   1.00000e-01,\n",
      "         1.00000e-02,   1.00000e-03,   1.00000e-04,   0.00000e+00])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:1531: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:454: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:599: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  best_estimator.fit(X, y, **self.fit_params)\n"
     ]
    }
   ],
   "source": [
    "#Prepare a Range of Alpha Values to Test\n",
    "alphas = np.array([100,10,1,0.1,0.01,0.001,0.0001,0])\n",
    "model=Lasso()\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid={'alpha': alphas,})\n",
    "#a dictionary for param_grid  feed the dictionary to alpha\n",
    "grid.fit(X,y)\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.92154009425\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "#this has to be wrong - a negitive number??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013545571017835822"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model=grid.best_estimator_\n",
    "best_model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "56cc8854-d722-411d-a6c7-e86310710f67"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cities were included in the study, Chicago, Cincinnati, Louisville, San Francisco, and Austin.  \n",
    "\n",
    "The cost of living index. Chicago = 111 Cincinnati = 83 Louisville = 91 Austin Tx = 78.26, and 189 in San Francisco.\n",
    "\n",
    "Median pay for a Data Scientist is $93,146. The range is 64,953-126,183 \n",
    "Chicago the median is 83,437. The range is 53,469-114.196 \n",
    "Austin the median 83,084. The range is 49,460 - 108,409 \n",
    "San Francisco the median salary is $112,468 and the range is 82,601-137,236\n",
    "\n",
    "This data is from www.payscale.com\n",
    "\n",
    "Originally I thought the cities  (especially San Francisco) would predict high salary and I was wrong.  I was surprised to see how many entry level jobs there were in San Francisco. \n",
    "\n",
    "The coefficients for the states for Low\n",
    "CA -.05\n",
    "OH .11\n",
    "TX .44\n",
    "IL .62\n",
    "\n",
    "The accuracy was .60 which was consistent with L1 and L2 results\n",
    "\n",
    "The coefficients for the states for High were all less than 1\n",
    "The precision of the model is .36\n",
    "\n",
    "\n",
    "I played with seeing if words would predict high and settled on the words senior, lead, and director.  These words imply responsibility and experience.  \n",
    "\n",
    "The coefficients were \n",
    "Senior = .32\n",
    "Lead = .45\n",
    "Director = .81\n",
    "\n",
    "I tried director alone and the coefficient was .77\n",
    "\n",
    "The accuracy was .61\n",
    "\n",
    "The confusion matrix results were\n",
    "True Positive: tested high and was high 1,700\n",
    "False Positive: Tested high and was low  64\n",
    "False Negative: Tested low and was high 1,100\n",
    "True Negative: Test negative and was negative  89\n",
    "\n",
    "The precision was .6 - when the model predicted high it was right 60% of the time.\n",
    "\n",
    "I tried to run the Lasso model and my output was wrong. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "fead9b5b-7316-405d-87fd-e144dff0cbeb"
   },
   "source": [
    "#### Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "12d5edeb-a272-43a0-9977-d951f12fedfb"
   },
   "source": [
    "#### Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary - which entries have the highest predicted salaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate the logistic regression model using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "#I used Count Vectorizer to get the words to use in the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "fec80936-37bc-4922-89bd-b5d615566c9c"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "d42b9fd8-39d5-416a-b40b-7410e6396c11"
   },
   "source": [
    "#### Re-test L1 and L2 regularization. You can use LogisticRegressionCV to find the optimal reguarlization parameters. \n",
    "- Re-test what text features are most valuable.  \n",
    "- How do L1 and L2 change the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "7570e237-c8cc-4e26-b569-7aee10627e79"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "e3a0c83d-e3b8-4bed-b864-7e795b34a3d4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
