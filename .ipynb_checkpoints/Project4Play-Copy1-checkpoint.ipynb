{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#soup = BeautifulSoup(urllib2.urlopen(base_url).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cities were included in the study, Chicago, Cincinnati, and Louisville.  Kentucky is very business friendly and it might be a positive cash flow to move south. Unfortunately there is a skill labor shortage in Louisville (according to my business owner brother in law)\n",
    "Cincinnati would be a good option.\n",
    "The cost of living index.\n",
    "Chicago = 111\n",
    "Cincinnati = 83\n",
    "Louisville = 91\n",
    "Austin Tx = 78.26\n",
    "\n",
    "Median pay for a Data Scientist is $93,146. The range is 64,953-126,183\n",
    "Chicago the median is 83,437. The reange is 53,469-114.196\n",
    "Austin the median 83,084. The range is 49,460 - 108,409\n",
    "This data is from www.payscale.com\n",
    "\n",
    "The following groupings were made\n",
    "Low end\n",
    "    Chicago:    55,000\n",
    "    Louisvile:  40,000\n",
    "    Cincinnati: 50,000, 55,000\n",
    "    Austin:     50,000\n",
    "    \n",
    "Middle\n",
    "    Chicago:    70,000  85,000\n",
    "    Louisvile:  60,000  80,000\n",
    "    Cincinnati: 65,000\n",
    "    Austin:     70,000  85,000\n",
    "    \n",
    "High pay\n",
    "    Chicago:    100,000  120,000\n",
    "    Louisvile:  100,000\n",
    "    Cincinnati:  90,000  110,000\n",
    "    Austin:     100,000  115,000\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',500)    # to remove column limit (Otherwise, we'll lose some info)\n",
    "df = pd.DataFrame()   # create a new data frame\n",
    "\n",
    "searchCriteria=[]\n",
    "salaryRange=[]\n",
    "jobTitle = []\n",
    "companyName=[]\n",
    "cityLocation=[]\n",
    "description=[]\n",
    "actualSalary=[]\n",
    "BackupsearchCriteria=[]\n",
    "BackupsalaryRange=[]\n",
    "BackupjobTitle = []\n",
    "BackupcompanyName=[]\n",
    "BackupcityLocation=[]\n",
    "Backupdescription=[]\n",
    "BackupactualSalary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "priceRanges = ['$55,000','$70,000','$85,000','$105,000','$120,000']\n",
    "\n",
    "for price in priceRanges:\n",
    "    time.sleep(1)   \n",
    "    base_url = 'http://www.indeed.com/q-data-scientist-'+ price +'-l-Chicago,-IL-jobs.html'\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    \n",
    "    if price == '$55,000':\n",
    "            level = 'low'\n",
    "    elif price == '$70,000' or price == '$85,000':\n",
    "            level = 'high'\n",
    "    else:\n",
    "            level = 'high'\n",
    "            \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "            \n",
    "#             for j in item('td', {'class': 'snip'}):\n",
    "#                      for k in j('nobr'):\n",
    "#                             actualSalary.append(k.get_text())\n",
    "            \n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Chicago 55\n"
     ]
    }
   ],
   "source": [
    "#55 and plus\n",
    "pVariableNu=10\n",
    "price = '$55,000'\n",
    "level='low'\n",
    "for pages in range(2,41):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = base_url='http://www.indeed.com/jobs?q=data+scientist+%2455%2C000&l=Chicago%2C+IL&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "#             for j in item('td', {'class': 'snip'}):\n",
    "#                      for k in j('nobr'):\n",
    "#                             actualSalary.append(k.get_text())\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "#             for j in item('td', {'class': 'snip'}):\n",
    "#                      for k in j('nobr'):\n",
    "#                         print k.get_text()\n",
    "#                         actualSalary.append(k.get_text())\n",
    "            \n",
    "\n",
    "# for i in soup('div', {'class': ' row result'}):\n",
    "#     for j in i('td', {'class': 'snip'}):\n",
    "#         for k in j('nobr'):\n",
    "#             print k.get_text()\n",
    "#             salary.append(k.get_text())\n",
    "\n",
    "print 'finished Chicago 55'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n",
      "394\n",
      "394\n",
      "394\n",
      "394\n",
      "394\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "finished Chicago 70\n"
     ]
    }
   ],
   "source": [
    "#70 and plus\n",
    "pVariableNu=10\n",
    "price = '$70,000'\n",
    "level='medium'\n",
    "#for pages in range(2,34):\n",
    "for pages in range(2,10):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    print pVariableNu\n",
    "  \n",
    "    #base_url = 'http://www.indeed.com/q-data-scientist-%2455%2C000&l=Chicago%2C+IL&start=' + pVariable + '&pp='\n",
    "    base_url='http://www.indeed.com/jobs?q=data+scientist+%2470%2C000&l=Chicago%2C+IL&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "print 'finished Chicago 70'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#companyName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470\n",
      "470\n",
      "470\n",
      "470\n",
      "470\n",
      "470\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470\n",
      "470\n"
     ]
    }
   ],
   "source": [
    "print len(jobTitle)\n",
    "print len(BackupjobTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Chicago 85\n"
     ]
    }
   ],
   "source": [
    "#85,000\n",
    "pVariableNu=10\n",
    "price = '$85,000'\n",
    "level = 'medium'\n",
    "for pages in range(2,26):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = base_url='http://www.indeed.com/jobs?q=data+scientist+%2485%2C000&l=Chicago%2C+IL&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "print 'finished Chicago 85'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Chicago 100\n"
     ]
    }
   ],
   "source": [
    "#100000\n",
    "pVariableNu=10\n",
    "price = '$100,000'\n",
    "level='high'\n",
    "for pages in range(2,18):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url =base_url='http://www.indeed.com/jobs?q=data+scientist+%24100%2C000&l=Chicago%2C+IL&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "print 'finished Chicago 100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826\n",
      "826\n",
      "826\n",
      "826\n",
      "826\n",
      "826\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(companyName)  ##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(0,624):\n",
    "#     print searchCriteria[i]\n",
    "#     print jobTitle[i]\n",
    "#     print companyName[i].lstrip().replace('\\n','')\n",
    "#     print cityLocation[i].replace('\\n','')\n",
    "#     print salaryRange[i]\n",
    "#     print description[i].replace('\\n','')\n",
    "#     print '\\n'\n",
    "# dictPostingsTEMP={'Search Criteria':searchCriteria,\n",
    "#               'Job Title':jobTitle,\n",
    "#               'Company Name':companyName,\n",
    "#               'City Location': cityLocation,\n",
    "#               'Salary Range': salaryRange, \n",
    "#               'Description':description}\n",
    "# searchListingsTEMP = pd.DataFrame(dictPostingsTEMP)\n",
    "# searchListingsTEMP.shape\n",
    "# (searchListingsTEMP.drop_duplicates(take_last=True)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#searchListingsTEMP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#searchListingsTEMP['Description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Chicago 120\n"
     ]
    }
   ],
   "source": [
    "#120000\n",
    "pVariableNu=10\n",
    "price = '$120,000'\n",
    "level='high'\n",
    "for pages in range(2,9):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = base_url='http://www.indeed.com/jobs?q=data+scientist+%24120%2C000&l=Chicago%2C+IL&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "print 'finished Chicago 120'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885\n",
      "885\n",
      "885\n",
      "885\n",
      "885\n",
      "885\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checking to make sure all is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(885, 6)\n",
      "(744, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: the take_last=True keyword is deprecated, use keep='last' instead\n"
     ]
    }
   ],
   "source": [
    "dictPostingsTEMP={'Search Criteria':searchCriteria,\n",
    "              'Job Title':jobTitle,\n",
    "              'Company Name':companyName,\n",
    "              'City Location':cityLocation,\n",
    "              'Salary Level': salaryRange, \n",
    "              'Description':description}\n",
    "\n",
    "searchListingsTEMP = pd.DataFrame(dictPostingsTEMP)\n",
    "print searchListingsTEMP.shape\n",
    "searchListingsTEMP=searchListingsTEMP.drop_duplicates(take_last=True)\n",
    "print searchListingsTEMP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Level</th>\n",
       "      <th>Search Criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Civis Analytics</td>\n",
       "      <td>\\nOur engineers, data scientists and analysts are not only the best and brightest in their fields, but are also eager to teach and learn from you....</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>high</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>Chicago, IL 60642 (Portage Park area)</td>\n",
       "      <td>NCSA Sports</td>\n",
       "      <td>\\nDesign, build and maintain reliable Ruby code within an existing Rails applicationSplit out small, well-defined services in smart and secure waysMentor other...</td>\n",
       "      <td>Senior Ruby on Rails Developer</td>\n",
       "      <td>high</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Vizient, Inc.</td>\n",
       "      <td>\\nProvides coordination for member risk adjustment task force include clinicians and data scientists. Works with member task force and Center for Advanced...</td>\n",
       "      <td>Director, Risk Adjustment</td>\n",
       "      <td>high</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Northbrook, IL</td>\n",
       "      <td>Astellas</td>\n",
       "      <td>\\nDevelop data mining and/or data modeling plans to support RWI&amp;A projects and programs. Manage, mentor and develop a high performing data scientists team through...</td>\n",
       "      <td>Director, RWI Data Science</td>\n",
       "      <td>high</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Strategic IT Staffing</td>\n",
       "      <td>\\nDoing all this with an exceptional group of software engineers, data scientists, dev-ops engineers and managers....</td>\n",
       "      <td>Senior DevOps Engineer</td>\n",
       "      <td>high</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             City Location           Company Name  \\\n",
       "880                            Chicago, IL        Civis Analytics   \n",
       "881  Chicago, IL 60642 (Portage Park area)            NCSA Sports   \n",
       "882                            Chicago, IL          Vizient, Inc.   \n",
       "883                         Northbrook, IL               Astellas   \n",
       "884                            Chicago, IL  Strategic IT Staffing   \n",
       "\n",
       "                                                                                                                                                               Description  \\\n",
       "880                  \\nOur engineers, data scientists and analysts are not only the best and brightest in their fields, but are also eager to teach and learn from you....   \n",
       "881     \\nDesign, build and maintain reliable Ruby code within an existing Rails applicationSplit out small, well-defined services in smart and secure waysMentor other...   \n",
       "882          \\nProvides coordination for member risk adjustment task force include clinicians and data scientists. Works with member task force and Center for Advanced...   \n",
       "883  \\nDevelop data mining and/or data modeling plans to support RWI&A projects and programs. Manage, mentor and develop a high performing data scientists team through...   \n",
       "884                                                  \\nDoing all this with an exceptional group of software engineers, data scientists, dev-ops engineers and managers....   \n",
       "\n",
       "                          Job Title Salary Level Search Criteria  \n",
       "880                 DevOps Engineer         high  data scientist  \n",
       "881  Senior Ruby on Rails Developer         high  data scientist  \n",
       "882       Director, Risk Adjustment         high  data scientist  \n",
       "883      Director, RWI Data Science         high  data scientist  \n",
       "884          Senior DevOps Engineer         high  data scientist  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListingsTEMP.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you read comments - so sad to say there are no 'real' Data Scientist jobs in \n",
    "Dayton, Ohio.  I had to resort to using Cincinnati data.  Oh well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished first page Cincy\n"
     ]
    }
   ],
   "source": [
    "################Cincinnati Ohio #####################################\n",
    "            \n",
    "priceRanges = ['$50,000','$55,000','$65,000','$90,000','$110,000']            \n",
    "for price in priceRanges:\n",
    "    time.sleep(1)   \n",
    "    base_url = 'http://www.indeed.com/q-data-scientist-'+price +'-l-Cincinnati,-OH-jobs.html'\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    \n",
    "    if price == '$50,000' or price == '$55,000':\n",
    "            level = 'low'\n",
    "    elif price == '$65,000':\n",
    "            level = 'medium'\n",
    "    else:\n",
    "            level = 'high'\n",
    "            \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "            \n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "        \n",
    "print 'finished first page Cincy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944\n",
      "944\n",
      "944\n",
      "944\n",
      "944\n",
      "944\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished cincy 50\n"
     ]
    }
   ],
   "source": [
    "#scraping the data from page 2 on for Cincy\n",
    "pVariableNu=10\n",
    "price = '$50,000'\n",
    "level='low'\n",
    "for pages in range(2,9):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/jobs?q=data+scientist+%2450%2C000&l=Cincinnati%2C+OH&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('low')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('low')\n",
    "            \n",
    "print 'finished cincy 50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009\n",
      "1009\n",
      "1009\n",
      "1009\n",
      "1009\n",
      "1009\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished cincy 55\n"
     ]
    }
   ],
   "source": [
    "#scraping the data from page 2 on for Cincy\n",
    "pVariableNu=10\n",
    "price = '$55,000'\n",
    "for pages in range(2,8):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/jobs?q=data+scientist+%2455%2C000&l=Cincinnati%2C+OH&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('low')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('low')\n",
    "            \n",
    "print 'finished cincy 55'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061\n",
      "1061\n",
      "1061\n",
      "1061\n",
      "1061\n",
      "1061\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished cincy 65\n"
     ]
    }
   ],
   "source": [
    "#scraping the data from page 2 on for Cincy\n",
    "pVariableNu=10\n",
    "price = '$65,000'\n",
    "level='medium'\n",
    "for pages in range(2,6):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/jobs?q=data+scientist+%2465%2C000&l=Cincinnati%2C+OH&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('medium')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('medium')\n",
    "print 'finished cincy 65'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098\n",
      "1098\n",
      "1098\n",
      "1098\n",
      "1098\n",
      "1098\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished cincy 90\n"
     ]
    }
   ],
   "source": [
    "#scraping the data from page 2 on for Cincy\n",
    "pVariableNu=10\n",
    "price = '$90,000'\n",
    "level = 'high'\n",
    "for pages in range(2,4):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/jobs?q=data+scientist+%2490%2C000&l=Cincinnati%2C+OH&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('high')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('high')\n",
    "print 'finished cincy 90'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116\n",
      "1116\n",
      "1116\n",
      "1116\n",
      "1116\n",
      "1116\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished cincy 110\n"
     ]
    }
   ],
   "source": [
    "#scraping the data from page 2 on for Cincy\n",
    "pVariableNu=10\n",
    "price = '$110,000'\n",
    "level = 'high'\n",
    "for pages in range(2,3):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/jobs?q=data+scientist+%24110%2C000&l=Cincinnati%2C+OH&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('high')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('high')\n",
    "print 'finished cincy 110'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1118\n",
      "1118\n",
      "1118\n",
      "1118\n",
      "1118\n",
      "1118\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Louisville, KY ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "got to 2\n",
      "finished first page louisville\n"
     ]
    }
   ],
   "source": [
    "############################Louisville KY##################\n",
    "            \n",
    "priceRanges = ['$40,000','$60,000','$80,000','$100,000','$120,000']            \n",
    "for price in priceRanges:\n",
    "    time.sleep(1)   \n",
    "    base_url ='http://www.indeed.com/q-data-scientist-'+price +'-l-Louisville,-KY-jobs.html'\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    \n",
    "    if price == '$40,000':\n",
    "            level = 'low'\n",
    "    elif price == '$60,000'  or price == '$80,000':\n",
    "            level = 'medium'\n",
    "    else:\n",
    "            level = 'high'\n",
    "            \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            print 'got to 2'\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "            \n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "        \n",
    "print 'finished first page louisville'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1178\n",
      "1178\n",
      "1178\n",
      "1178\n",
      "1178\n",
      "1178\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished louisville 40\n"
     ]
    }
   ],
   "source": [
    "pVariableNu=10\n",
    "price = '$40,000'\n",
    "level = 'low'\n",
    "for pages in range(2,3):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url ='http://www.indeed.com/jobs?q=data+scientist+%2440%2C000&l=Louisville%2C+KY&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('low')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('low')\n",
    "print 'finished louisville 40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1186\n",
      "1186\n",
      "1186\n",
      "1186\n",
      "1186\n",
      "1186\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got to 1\n",
      "finished louisville 60\n"
     ]
    }
   ],
   "source": [
    "pVariableNu=10\n",
    "price = '$60,000'\n",
    "level = 'medium'\n",
    "for pages in range(2,3):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url ='http://www.indeed.com/jobs?q=data+scientist+%2460%2C000&l=Louisville%2C+KY&start='+pVariable+'&pp='\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    print 'got to 1'\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('medium')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('medium')\n",
    "print 'finished louisville 60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195\n",
      "1195\n",
      "1195\n",
      "1195\n",
      "1195\n",
      "1195\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Austin Texas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################### Austin TX ###########################\n",
    "priceRanges = ['$50,000','$70,000','$85,000','$100,000','$115,000']\n",
    "\n",
    "for price in priceRanges:\n",
    "    time.sleep(1)   \n",
    "    base_url = 'http://www.indeed.com/q-data-scientist-'+ price +'-l-Austin,-TX-jobs.html'\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    \n",
    "    if price == '$50,000':\n",
    "            level = 'low'\n",
    "    elif price == '$70,000' or price == '$85,000':\n",
    "            level = 'medium'\n",
    "    else:\n",
    "            level = 'high'\n",
    "            \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "            \n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(level)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1254\n",
      "1254\n",
      "1254\n",
      "1254\n",
      "1254\n",
      "1254\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pVariableNu=10\n",
    "price = '$50,000'\n",
    "level='low'\n",
    "for pages in range(2,17):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url ='http://www.indeed.com/jobs?q=data+scientist+%2450%2C000&l=Austin%2C+TX&start='+pVariable+'#'\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('low')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1388\n",
      "1388\n",
      "1388\n",
      "1388\n",
      "1388\n",
      "1388\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pVariableNu=10\n",
    "price = '$70,000'\n",
    "level='medium'\n",
    "for pages in range(2,13):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url ='http://www.indeed.com/jobs?q=data+scientist+%2470%2C000&l=Austin%2C+TX&start='+pVariable+'#'\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('medium')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480\n",
      "1480\n",
      "1480\n",
      "1480\n",
      "1480\n",
      "1480\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pVariableNu=10\n",
    "price = '$85,000'\n",
    "level='medium'\n",
    "for pages in range(2,10):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url ='http://www.indeed.com/jobs?q=data+scientist+%2485%2C000&l=Austin%2C+TX&start='+pVariable+'#'\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('medium')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1547\n",
      "1547\n",
      "1547\n",
      "1547\n",
      "1547\n",
      "1547\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BackupsearchCriteria =searchCriteria \n",
    "BackupsalaryRange=salaryRange\n",
    "BackupjobTitle =jobTitle\n",
    "BackupcompanyName=companyName\n",
    "BackupcityLocation=cityLocation\n",
    "Backupdescription=description\n",
    "BackupactualSalary=actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pVariableNu=10\n",
    "price = '$100,000'\n",
    "level='high'\n",
    "for pages in range(2,7):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url ='http://www.indeed.com/jobs?q=data+scientist+%24100%2C000&l=Austin%2C+TX&start='+pVariable+'#'\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('high')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592\n",
      "1592\n",
      "1592\n",
      "1592\n",
      "1592\n",
      "1592\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pVariableNu=10\n",
    "price = '$115,000'\n",
    "level='high'\n",
    "for pages in range(2,4):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url ='http://www.indeed.com/jobs?q=data+scientist+%24115%2C000&l=Austin%2C+TX&start='+pVariable+'#'\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('high')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking to make sure all is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610\n",
      "1610\n",
      "1610\n",
      "1610\n",
      "1610\n",
      "1610\n"
     ]
    }
   ],
   "source": [
    "print len(searchCriteria)\n",
    "print len(jobTitle)\n",
    "print len(companyName)\n",
    "print len(cityLocation)\n",
    "print len(salaryRange)\n",
    "print len(description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1610, 6)\n",
      "(1284, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: the take_last=True keyword is deprecated, use keep='last' instead\n"
     ]
    }
   ],
   "source": [
    "dictPostings={'Search Criteria':searchCriteria,\n",
    "              'Job Title':jobTitle,\n",
    "              'Company Name':companyName,\n",
    "              'City Location':cityLocation,\n",
    "              'Salary Level': salaryRange, \n",
    "              'Description':description}\n",
    "\n",
    "searchListings = pd.DataFrame(dictPostings)\n",
    "print searchListings.shape\n",
    "searchListings=searchListings.drop_duplicates(take_last=True)\n",
    "print searchListings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(0,10):\n",
    "#     print searchCriteria[i]\n",
    "#     print jobTitle[i]\n",
    "#     print companyName[i].lstrip().replace('\\n','')\n",
    "#     print cityLocation[i].replace('\\n','')\n",
    "#     print salaryRange[i]\n",
    "#     print description[i].replace('\\n','')\n",
    "#     print '\\n''\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'City Location', u'Company Name', u'Description', u'Job Title',\n",
       "       u'Salary Level', u'Search Criteria'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Level</th>\n",
       "      <th>Search Criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Precima</td>\n",
       "      <td>The Data Scientist will provide process execution support for client projects. Take analytical objectives and define data requirements....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chicago, IL 60601</td>\n",
       "      <td>HERE</td>\n",
       "      <td>With big data in Hadoop and/or Spark for data extraction and data prep for. Solutions and organizing teams of other data scientists and engineers to....</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lake Forest, IL</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>Professional experience analyzing data and generating relevant and actionable insights. Bachelors Degree required (Business, Data Analytics or Supply-Chain...</td>\n",
       "      <td>Data Scientist - Abbott Nutrition - Lake Forest, IL</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>The University of Chicago Medicine</td>\n",
       "      <td>\\nThe Data Scientist will also be responsible for data profiling/cleansing data governance consultation, data quality assessment, data mart mapping and data...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Digital Factory</td>\n",
       "      <td>\\nChief Data Scientist*. We are looking for an experienced Data Scientist that will work with the Research/Development teams to provide insights into mobile data...</td>\n",
       "      <td>Chief Data Scientist (equity position)</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>GE Transportation</td>\n",
       "      <td>\\nThe Senior Data Scientist will demonstrate leadership in communicating business goals, programs, and processes for multiple areas or business / market segments....</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Anomalix</td>\n",
       "      <td>\\nData Scientist Responsibilities will include:. Anomalix is looking for strong data scientist candidates to join a team building out our flagship enterprise...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>C R Research Services</td>\n",
       "      <td>\\nParticipate in the development of final written reports that involve presentation set-up and data posting. Coordinate all aspects of primary research projects...</td>\n",
       "      <td>Quantitative Research Analyst</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Synchrony Financial</td>\n",
       "      <td>\\nWe are looking for scientists who are curious and passionate about mining data and have experience in statistical programming, SAS, machine learning, and use of...</td>\n",
       "      <td>AVP, Credit Innovation Data Scientist (L11)</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>KIPP Chicago</td>\n",
       "      <td>\\nA data scientist, modeling analyst, or data analyst to join our data science team at our regional headquarters in Chicago....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Kaplan</td>\n",
       "      <td>\\nMetis Senior Data Scientists provide incredible and inspiring Data Science instruction; We are looking for Senior Data Scientists to be part of the Metis Data...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Inficare</td>\n",
       "      <td>\\nBe a key component of the Big Data and Data Sciences CoE, working directly with clients to solve varied business issues using internal and external data....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>low</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Precima</td>\n",
       "      <td>The Data Scientist will provide process execution support for client projects. Take analytical objectives and define data requirements....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>medium</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lake Forest, IL</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>Professional experience analyzing data and generating relevant and actionable insights. Bachelors Degree required (Business, Data Analytics or Supply-Chain...</td>\n",
       "      <td>Data Scientist - Abbott Nutrition - Lake Forest, IL</td>\n",
       "      <td>medium</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chicago, IL 60601 (Loop area)</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>\\nKPMG is currently seeking a Data Scientist, to join our Advanced Data Analytics in our Chicago, IL office. Eight years of professional experience working as a...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>medium</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    City Location                        Company Name  \\\n",
       "0                     Chicago, IL                             Precima   \n",
       "1               Chicago, IL 60601                                HERE   \n",
       "2                 Lake Forest, IL                 ABBOTT LABORATORIES   \n",
       "3                     Chicago, IL  The University of Chicago Medicine   \n",
       "4                     Chicago, IL                     Digital Factory   \n",
       "5                     Chicago, IL                   GE Transportation   \n",
       "6                     Chicago, IL                            Anomalix   \n",
       "7                     Chicago, IL               C R Research Services   \n",
       "8                     Chicago, IL                 Synchrony Financial   \n",
       "9                     Chicago, IL                        KIPP Chicago   \n",
       "10                    Chicago, IL                              Kaplan   \n",
       "11                    Chicago, IL                            Inficare   \n",
       "12                    Chicago, IL                             Precima   \n",
       "14                Lake Forest, IL                 ABBOTT LABORATORIES   \n",
       "21  Chicago, IL 60601 (Loop area)                                KPMG   \n",
       "\n",
       "                                                                                                                                                              Description  \\\n",
       "0                              The Data Scientist will provide process execution support for client projects. Take analytical objectives and define data requirements....   \n",
       "1                With big data in Hadoop and/or Spark for data extraction and data prep for. Solutions and organizing teams of other data scientists and engineers to....   \n",
       "2         Professional experience analyzing data and generating relevant and actionable insights. Bachelors Degree required (Business, Data Analytics or Supply-Chain...   \n",
       "3         \\nThe Data Scientist will also be responsible for data profiling/cleansing data governance consultation, data quality assessment, data mart mapping and data...   \n",
       "4    \\nChief Data Scientist*. We are looking for an experienced Data Scientist that will work with the Research/Development teams to provide insights into mobile data...   \n",
       "5   \\nThe Senior Data Scientist will demonstrate leadership in communicating business goals, programs, and processes for multiple areas or business / market segments....   \n",
       "6        \\nData Scientist Responsibilities will include:. Anomalix is looking for strong data scientist candidates to join a team building out our flagship enterprise...   \n",
       "7     \\nParticipate in the development of final written reports that involve presentation set-up and data posting. Coordinate all aspects of primary research projects...   \n",
       "8   \\nWe are looking for scientists who are curious and passionate about mining data and have experience in statistical programming, SAS, machine learning, and use of...   \n",
       "9                                         \\nA data scientist, modeling analyst, or data analyst to join our data science team at our regional headquarters in Chicago....   \n",
       "10    \\nMetis Senior Data Scientists provide incredible and inspiring Data Science instruction; We are looking for Senior Data Scientists to be part of the Metis Data...   \n",
       "11         \\nBe a key component of the Big Data and Data Sciences CoE, working directly with clients to solve varied business issues using internal and external data....   \n",
       "12                             The Data Scientist will provide process execution support for client projects. Take analytical objectives and define data requirements....   \n",
       "14        Professional experience analyzing data and generating relevant and actionable insights. Bachelors Degree required (Business, Data Analytics or Supply-Chain...   \n",
       "21    \\nKPMG is currently seeking a Data Scientist, to join our Advanced Data Analytics in our Chicago, IL office. Eight years of professional experience working as a...   \n",
       "\n",
       "                                              Job Title Salary Level  \\\n",
       "0                                        Data Scientist          low   \n",
       "1                              Principal Data Scientist          low   \n",
       "2   Data Scientist - Abbott Nutrition - Lake Forest, IL          low   \n",
       "3                                        Data Scientist          low   \n",
       "4                Chief Data Scientist (equity position)          low   \n",
       "5                                 Senior Data Scientist          low   \n",
       "6                                        Data Scientist          low   \n",
       "7                         Quantitative Research Analyst          low   \n",
       "8           AVP, Credit Innovation Data Scientist (L11)          low   \n",
       "9                                        Data Scientist          low   \n",
       "10                                Senior Data Scientist          low   \n",
       "11                                       Data Scientist          low   \n",
       "12                                       Data Scientist       medium   \n",
       "14  Data Scientist - Abbott Nutrition - Lake Forest, IL       medium   \n",
       "21                                       Data Scientist       medium   \n",
       "\n",
       "   Search Criteria  \n",
       "0   data scientist  \n",
       "1   data scientist  \n",
       "2   data scientist  \n",
       "3   data scientist  \n",
       "4   data scientist  \n",
       "5   data scientist  \n",
       "6   data scientist  \n",
       "7   data scientist  \n",
       "8   data scientist  \n",
       "9   data scientist  \n",
       "10  data scientist  \n",
       "11  data scientist  \n",
       "12  data scientist  \n",
       "14  data scientist  \n",
       "21  data scientist  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListings.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610\n",
      "1610\n"
     ]
    }
   ],
   "source": [
    "print len(cityLocation)\n",
    "print len(searchCriteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if time\n",
    "# salary = []\n",
    "# for i in soup('div', {'class': ' row result'}):\n",
    "#     for j in i('td', {'class': 'snip'}):\n",
    "#         for k in j('nobr'):\n",
    "#             print k.get_text()\n",
    "#             salary.append(k.get_text())\n",
    "            \n",
    "             \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searchListings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searchListings.columns=['City Location', 'Company Name',\n",
    "                       'Description','Job Title','Salary Range',\n",
    "                       'Search Criteria']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'City Location', u'Company Name', u'Description', u'Job Title',\n",
       "       u'Salary Level', u'Search Criteria'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(searchListings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(searchListings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write to csv  for safety\n",
    "import csv\n",
    "searchListings.to_csv('~/Documents/SearchListingsBackup.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create dummies for salary range\n",
    "\n",
    "salaryDummies = pd.get_dummies(searchListings['Salary Level'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(salaryDummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   high  low  medium\n",
       "0   0.0  1.0     0.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaryDummies.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1284.000000</td>\n",
       "      <td>1284.000000</td>\n",
       "      <td>1284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.211059</td>\n",
       "      <td>0.453271</td>\n",
       "      <td>0.335670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.408219</td>\n",
       "      <td>0.498006</td>\n",
       "      <td>0.472408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              high          low       medium\n",
       "count  1284.000000  1284.000000  1284.000000\n",
       "mean      0.211059     0.453271     0.335670\n",
       "std       0.408219     0.498006     0.472408\n",
       "min       0.000000     0.000000     0.000000\n",
       "25%       0.000000     0.000000     0.000000\n",
       "50%       0.000000     0.000000     0.000000\n",
       "75%       0.000000     1.000000     1.000000\n",
       "max       1.000000     1.000000     1.000000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaryDummies.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'high', u'low', u'medium'], dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaryDummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#salaryDummiesPD=pd.DataFrame(salaryDummies, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "salaryDummiesPD.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searchListingsFinal=pd.concat([searchListings, salaryDummies],axis =1)\n",
    "#searchListingsFinal=pd.DataFrame(searchListings).join(pd.DataFrame(salaryDummies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(salaryDummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Civis Analytics                                          60\n",
       "IBM                                                      29\n",
       "Amazon Corporate LLC                                     27\n",
       "Allstate Insurance                                       25\n",
       "University of Chicago                                    24\n",
       "CDK Global                                               22\n",
       "University of Texas at Austin                            20\n",
       "Workbridge Associates                                    20\n",
       "Tempus                                                   18\n",
       "Procter & Gamble                                         17\n",
       "Jobspring Partners                                       16\n",
       "HomeAway                                                 16\n",
       "Indeed                                                   15\n",
       "P&G                                                      15\n",
       "Morningstar                                              14\n",
       "HDR                                                      14\n",
       "MaxPoint                                                 13\n",
       "Cincinnati Children's Hospital                           13\n",
       "GE Digital                                               12\n",
       "Saudi Aramco                                             12\n",
       "Google                                                   12\n",
       "National Opinion Research Center (NORC)                  11\n",
       "HERE                                                     11\n",
       "KPMG                                                     11\n",
       "Astellas Pharmaceuticals                                 11\n",
       "Accenture                                                10\n",
       "Asuragen                                                  9\n",
       "Next Step Systems                                         9\n",
       "NCSA Athletic Recruiting                                  7\n",
       "GE Aviation                                               7\n",
       "                                                         ..\n",
       "Collaborative for Academic, Social, and Emotional...      1\n",
       "The University of Texas at Austin                         1\n",
       "ACGT, Inc.                                                1\n",
       "Talis Group                                               1\n",
       "Arcadis:US                                                1\n",
       "DNA Diagnostics Center                                    1\n",
       "Kelton Global                                             1\n",
       "LabPersonnel                                              1\n",
       "KIPP Chicago                                              1\n",
       "Fuchs Lubricants Co.                                      1\n",
       "Rosalind Franklin University of Medicine and Scien...     1\n",
       "Merkle Inc.                                               1\n",
       "S.C. International                                        1\n",
       "Mars                                                      1\n",
       "Acxiom                                                    1\n",
       "Dept of State Health Services                             1\n",
       "Modis                                                     1\n",
       "Umbel                                                     1\n",
       "Aon                                                       1\n",
       "SC Business Unit 3                                        1\n",
       "Galvanize                                                 1\n",
       "Levy Restaurant Limited Partnership                       1\n",
       "Eldorado Trading, LLC                                     1\n",
       "Beam Inc.                                                 1\n",
       "Creative Circle                                           1\n",
       "A2Z Development Center, Inc.                              1\n",
       "Olenick & Associates                                      1\n",
       "AMITA Health Adventist Medical Center, Hinsdale- A...     1\n",
       "SoCore Energy                                             1\n",
       "Olam Americas, Inc.                                       1\n",
       "Name: Company Name, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListingsFinal['Company Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 9)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListingsFinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: FutureWarning: the take_last=True keyword is deprecated, use keep='last' instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "searchListingsFinal= searchListingsFinal.drop_duplicates(take_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 9)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListingsFinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searchListingsFinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write to csv  for safety\n",
    "import csv\n",
    "searchListingsFinal.to_csv('~/Documents/SearchListings.csv', encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searchListingsFinal.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
