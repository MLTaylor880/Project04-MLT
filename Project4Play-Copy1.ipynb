{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#base_url = 'http://www.indeed.com/q-data-scientist-$70,000-l-Chicago,-IL-jobs.html'\n",
    "\n",
    "# pd.set_option('max_colwidth',500)    # to remove column limit (Otherwise, we'll lose some info)\n",
    "# df = pd.DataFrame()   # create a new data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(urllib2.urlopen(base_url).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-48b7fe9df999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'/n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "# for table in soup('table'):\n",
    "#     print table\n",
    "#     print '/n'\n",
    "# print len(soup('table'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for ptag in soup('span',{'class': 'company'}):\n",
    "#         print ptag.text\n",
    "#         print '\\n'\n",
    "# for ptag in soup('span',{'class': 'jobtitle turnstileLink'}):\n",
    "#         print ptag.text\n",
    "#         print '\\n'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',500)    # to remove column limit (Otherwise, we'll lose some info)\n",
    "df = pd.DataFrame()   # create a new data frame\n",
    "\n",
    "searchCriteria=[]\n",
    "salaryRange=[]\n",
    "jobTitle = []\n",
    "companyName=[]\n",
    "cityLocation=[]\n",
    "description=[]\n",
    "actualSalary=[]\n",
    "priceRanges = ['$55,000','$70,000','$85,000','$105,000','$120,000']\n",
    "\n",
    "for price in priceRanges:\n",
    "    time.sleep(1)   \n",
    "    base_url = 'http://www.indeed.com/q-data-scientist-'+ price +'-l-Chicago,-IL-jobs.html'\n",
    "\n",
    "    pd.set_option('max_colwidth',500)    # to remove column limit (Otherwise, we'll lose some info)\n",
    "    df = pd.DataFrame()   # create a new data frame\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "      \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "#             for j in item('td', {'class': 'snip'}):\n",
    "#                      for k in j('nobr'):\n",
    "#                             actualSalary.append(k.get_text())\n",
    "            \n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "#             for j in item('td', {'class': 'snip'}):\n",
    "#                      for k in j('nobr'):\n",
    "#                             actualSalary.append(k.get_text())\n",
    "\n",
    "#     gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "#     for item in gData:\n",
    "#             for i in soup('div', {'class': ' row result'}):\n",
    "#                 for j in i('td', {'class': 'snip'}):\n",
    "#                     for k in j('nobr'):\n",
    "#                         print k.get_text()\n",
    "#                         actualSalary.append(k.get_text())\n",
    "\n",
    "\n",
    "# for i in range(0,len(jobTitle)):\n",
    "#     print searchCriteria[i]\n",
    "#     print jobTitle[i]\n",
    "#     print companyName[i].lstrip().replace('\\n','')\n",
    "#     print cityLocation[i].replace('\\n','')\n",
    "#     print salaryRange[i]\n",
    "#     print description[i].replace('\\n','')\n",
    "#     print '\\n''\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Chicago 55\n"
     ]
    }
   ],
   "source": [
    "#55 and plus\n",
    "pVariableNu=20\n",
    "price = '$55,000'\n",
    "for pages in range(2,41):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/q-data-scientist-%2455%2C000&l=Chicago%2C+IL&start=' + pVariable + '&pp='\n",
    "    \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('price')\n",
    "#             for j in item('td', {'class': 'snip'}):\n",
    "#                      for k in j('nobr'):\n",
    "#                             actualSalary.append(k.get_text())\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "#             for j in item('td', {'class': 'snip'}):\n",
    "#                      for k in j('nobr'):\n",
    "#                         print k.get_text()\n",
    "#                         actualSalary.append(k.get_text())\n",
    "            \n",
    "\n",
    "# for i in soup('div', {'class': ' row result'}):\n",
    "#     for j in i('td', {'class': 'snip'}):\n",
    "#         for k in j('nobr'):\n",
    "#             print k.get_text()\n",
    "#             salary.append(k.get_text())\n",
    "\n",
    "print 'finished Chicago 55'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1104"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(companyName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Chicago 70\n"
     ]
    }
   ],
   "source": [
    "#70 and plus\n",
    "pVariableNu=20\n",
    "price = '$70,000'\n",
    "for pages in range(2,34):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/q-data-scientist-%2455%2C000&l=Chicago%2C+IL&start=' + pVariable + '&pp='\n",
    "    \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('price')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "print 'finished Chicago 70'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Chicago 85\n"
     ]
    }
   ],
   "source": [
    "#85,000\n",
    "pVariableNu=20\n",
    "price = '$85,000'\n",
    "for pages in range(2,26):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/q-data-scientist-%2455%2C000&l=Chicago%2C+IL&start=' + pVariable + '&pp='\n",
    "    \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('price')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "print 'finished Chicago 85'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Chicago 100\n"
     ]
    }
   ],
   "source": [
    "#100000\n",
    "pVariableNu=20\n",
    "price = '$100,000'\n",
    "for pages in range(2,18):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/q-data-scientist-%2455%2C000&l=Chicago%2C+IL&start=' + pVariable + '&pp='\n",
    "    \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('price')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "print 'finished Chicago 100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Chicago 120\n"
     ]
    }
   ],
   "source": [
    "#120000\n",
    "pVariableNu=20\n",
    "price = '$120,000'\n",
    "for pages in range(2,9):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/q-data-scientist-%2455%2C000&l=Chicago%2C+IL&start=' + pVariable + '&pp='\n",
    "    \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('price')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "print 'finished Chicago 120'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you read comments - so sad to say there are no 'real' Data Scientist jobs in \n",
    "Dayton, Ohio.  I had to resort to using Cincinnati data.  Oh well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished first page Cincy\n"
     ]
    }
   ],
   "source": [
    "priceRanges = ['$45,000','$50,000','$65,000','$80,000','$110,000']\n",
    "\n",
    "for price in priceRanges:\n",
    "    time.sleep(1)   \n",
    "    base_url = 'http://www.indeed.com/q-data-scientist-'+price +'-l-Cincinnati,-OH-jobs.html'\n",
    "    pd.set_option('max_colwidth',500)    # to remove column limit (Otherwise, we'll lose some info)\n",
    "    df = pd.DataFrame()   # create a new data frame\n",
    "    soup = BeautifulSoup(urllib2.urlopen(base_url).read())\n",
    "      \n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "            \n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append((item.find_all(\"span\",{\"class\":\"company\"})[0].text).lstrip().replace('\\n',''))\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "print 'finished first page Cincy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished cincy 45\n"
     ]
    }
   ],
   "source": [
    "#scraping the data from page 2 on for Cincy\n",
    "pVariableNu=20\n",
    "price = '$45,000'\n",
    "for pages in range(2,9):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "    base_url = 'http://www.indeed.com/jobs?q=data+scientist+%2445%2C000&l=Cincinnati%2C+OH&start='+pVariable+'&pp='\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('price')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "print 'finished cincy 45'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished cincy 50\n"
     ]
    }
   ],
   "source": [
    "#scraping the data from page 2 on for Cincy\n",
    "pVariableNu=20\n",
    "price = '$50,000'\n",
    "for pages in range(2,9):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "  #  base_url = 'http://www.indeed.com/q-data-scientist-%2455%2C000&l=Chicago%2C+IL&start=' + pVariable + '&pp='\n",
    "    base_url = 'http://www.indeed.com/jobs?q=data+scientist+%2445%2C000&l=Cincinnati%2C+OH&start='+pVariable+'&pp='\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('price')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "print 'finished cincy 50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished cincy 65\n"
     ]
    }
   ],
   "source": [
    "#scraping the data from page 2 on for Cincy\n",
    "pVariableNu=20\n",
    "price = '$65,000'\n",
    "for pages in range(2,6):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "  #  base_url = 'http://www.indeed.com/q-data-scientist-%2455%2C000&l=Chicago%2C+IL&start=' + pVariable + '&pp='\n",
    "    base_url = 'http://www.indeed.com/jobs?q=data+scientist+%2445%2C000&l=Cincinnati%2C+OH&start='+pVariable+'&pp='\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('price')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "print 'finished cincy 65'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished cincy 80\n"
     ]
    }
   ],
   "source": [
    "#scraping the data from page 2 on for Cincy\n",
    "pVariableNu=20\n",
    "price = '$80,000'\n",
    "for pages in range(2,4):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "  #  base_url = 'http://www.indeed.com/q-data-scientist-%2455%2C000&l=Chicago%2C+IL&start=' + pVariable + '&pp='\n",
    "    base_url = 'http://www.indeed.com/jobs?q=data+scientist+%2445%2C000&l=Cincinnati%2C+OH&start='+pVariable+'&pp='\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('price')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "print 'finished cincy 80'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished cincy 110\n"
     ]
    }
   ],
   "source": [
    "#scraping the data from page 2 on for Cincy\n",
    "pVariableNu=20\n",
    "price = '$110,000'\n",
    "for pages in range(2,3):\n",
    "    time.sleep(2) \n",
    "    pVariableNu=10+pVariableNu\n",
    "    pVariable=str(pVariableNu)\n",
    "    \n",
    "  #  base_url = 'http://www.indeed.com/q-data-scientist-%2455%2C000&l=Chicago%2C+IL&start=' + pVariable + '&pp='\n",
    "    base_url = 'http://www.indeed.com/jobs?q=data+scientist+%2445%2C000&l=Cincinnati%2C+OH&start='+pVariable+'&pp='\n",
    "    gData = soup.find_all(\"div\",{\"class\":\"row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append('price')\n",
    "\n",
    "    gData = soup.find_all(\"div\",{\"class\":\" row result\"})\n",
    "    for item in gData:\n",
    "            searchCriteria.append('data scientist')\n",
    "            jobTitle.append(item.find_all(\"a\",{\"data-tn-element\":\"jobTitle\"})[0].text)\n",
    "            companyName.append(item.find_all(\"span\",{\"class\":\"company\"})[0].text)\n",
    "            cityLocation.append(item.find_all(\"span\",{\"class\":\"location\"})[0].text)\n",
    "            description.append(item.find_all(\"span\",{\"class\":\"summary\"})[0].text)\n",
    "            salaryRange.append(price)\n",
    "print 'finished cincy 110'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fixing my problem of lists by making them dataframes\n",
    "dictPostings={'Search Criteria':searchCriteria,\n",
    "              'Job Title':jobTitle,\n",
    "              'Company Name':companyName,\n",
    "              'City Location': cityLocation,\n",
    "              'Salary Range': salaryRange, \n",
    "              'Description':description}\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# for i in range(0,10):\n",
    "#     print searchCriteria[i]\n",
    "#     print jobTitle[i]\n",
    "#     print companyName[i].lstrip().replace('\\n','')\n",
    "#     print cityLocation[i].replace('\\n','')\n",
    "#     print salaryRange[i]\n",
    "#     print description[i].replace('\\n','')\n",
    "#     print '\\n''\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searchListings = pd.DataFrame(dictPostings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>Search Criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicago, IL 60601</td>\n",
       "      <td>HERE</td>\n",
       "      <td>With big data in Hadoop and/or Spark for data extraction and data prep for. Solutions and organizing teams of other data scientists and engineers to....</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>$55,000</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Northbrook, IL 60062</td>\n",
       "      <td>Allstate Insurance</td>\n",
       "      <td>The Data Scientist family is accountable for using data to make decisions, which includes building predictive models and developing new machine learning...</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>$55,000</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago, IL 60601</td>\n",
       "      <td>Allstate Insurance</td>\n",
       "      <td>Manages data and data requests to improve the accuracy of our data and decisions made from data analysis. Strong understanding of geospatial data....</td>\n",
       "      <td>Geospatial Data Scientist</td>\n",
       "      <td>$55,000</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>KIPP Chicago</td>\n",
       "      <td>\\nA data scientist, modeling analyst, or data analyst to join our data science team at our regional headquarters in Chicago....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$55,000</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Digital Factory</td>\n",
       "      <td>\\nChief Data Scientist*. We are looking for an experienced Data Scientist that will work with the Research/Development teams to provide insights into mobile data...</td>\n",
       "      <td>Chief Data Scientist (equity position)</td>\n",
       "      <td>$55,000</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          City Location        Company Name  \\\n",
       "0     Chicago, IL 60601                HERE   \n",
       "1  Northbrook, IL 60062  Allstate Insurance   \n",
       "2     Chicago, IL 60601  Allstate Insurance   \n",
       "3           Chicago, IL        KIPP Chicago   \n",
       "4           Chicago, IL     Digital Factory   \n",
       "\n",
       "                                                                                                                                                            Description  \\\n",
       "0              With big data in Hadoop and/or Spark for data extraction and data prep for. Solutions and organizing teams of other data scientists and engineers to....   \n",
       "1           The Data Scientist family is accountable for using data to make decisions, which includes building predictive models and developing new machine learning...   \n",
       "2                 Manages data and data requests to improve the accuracy of our data and decisions made from data analysis. Strong understanding of geospatial data....   \n",
       "3                                       \\nA data scientist, modeling analyst, or data analyst to join our data science team at our regional headquarters in Chicago....   \n",
       "4  \\nChief Data Scientist*. We are looking for an experienced Data Scientist that will work with the Research/Development teams to provide insights into mobile data...   \n",
       "\n",
       "                                Job Title Salary Range Search Criteria  \n",
       "0                Principal Data Scientist      $55,000  data scientist  \n",
       "1                   Junior Data Scientist      $55,000  data scientist  \n",
       "2               Geospatial Data Scientist      $55,000  data scientist  \n",
       "3                          Data Scientist      $55,000  data scientist  \n",
       "4  Chief Data Scientist (equity position)      $55,000  data scientist  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978\n",
      "1978\n"
     ]
    }
   ],
   "source": [
    "print len(cityLocation)\n",
    "print len(searchCriteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if time\n",
    "# salary = []\n",
    "# for i in soup('div', {'class': ' row result'}):\n",
    "#     for j in i('td', {'class': 'snip'}):\n",
    "#         for k in j('nobr'):\n",
    "#             print k.get_text()\n",
    "#             salary.append(k.get_text())\n",
    "            \n",
    "             \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/marthataylor/DSI-CHI-1/Project04-MLT'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>Search Criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicago, IL 60601</td>\n",
       "      <td>HERE</td>\n",
       "      <td>With big data in Hadoop and/or Spark for data extraction and data prep for. Solutions and organizing teams of other data scientists and engineers to....</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>$55,000</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City Location Company Name  \\\n",
       "0  Chicago, IL 60601         HERE   \n",
       "\n",
       "                                                                                                                                                Description  \\\n",
       "0  With big data in Hadoop and/or Spark for data extraction and data prep for. Solutions and organizing teams of other data scientists and engineers to....   \n",
       "\n",
       "                  Job Title Salary Range Search Criteria  \n",
       "0  Principal Data Scientist      $55,000  data scientist  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searchListings.columns=['City Location', 'Company Name',\n",
    "                       'Description','Job Title','Salary Range',\n",
    "                       'Search Criteria']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'City Location', u'Company Name', u'Description', u'Job Title',\n",
       "       u'Salary Range', u'Search Criteria'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchListings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\u2019' in position 5: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9c87b6dbecac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#write to csv  for safety\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msearchListings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/Documents/SearchListings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[1;32m   1342\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1344\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m   1676\u001b[0m                                         quoting=self.quoting)\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1678\u001b[0;31m         \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;31m# from collections import namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/lib.pyx\u001b[0m in \u001b[0;36mpandas.lib.write_csv_rows (pandas/lib.c:19850)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\u2019' in position 5: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "#write to csv  for safety\n",
    "import csv\n",
    "searchListings.to_csv('~/Documents/SearchListings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create dummies for salary range\n",
    "\n",
    "salaryDummies = pd.get_dummies(searchListings['Salary Range'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$100,000</th>\n",
       "      <th>$105,000</th>\n",
       "      <th>$110,000</th>\n",
       "      <th>$120,000</th>\n",
       "      <th>$45,000</th>\n",
       "      <th>$50,000</th>\n",
       "      <th>$55,000</th>\n",
       "      <th>$65,000</th>\n",
       "      <th>$70,000</th>\n",
       "      <th>$80,000</th>\n",
       "      <th>$85,000</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   $100,000  $105,000  $110,000  $120,000  $45,000  $50,000  $55,000  $65,000  \\\n",
       "0       0.0       0.0       0.0       0.0      0.0      0.0      1.0      0.0   \n",
       "1       0.0       0.0       0.0       0.0      0.0      0.0      1.0      0.0   \n",
       "2       0.0       0.0       0.0       0.0      0.0      0.0      1.0      0.0   \n",
       "3       0.0       0.0       0.0       0.0      0.0      0.0      1.0      0.0   \n",
       "\n",
       "   $70,000  $80,000  $85,000  price  \n",
       "0      0.0      0.0      0.0    0.0  \n",
       "1      0.0      0.0      0.0    0.0  \n",
       "2      0.0      0.0      0.0    0.0  \n",
       "3      0.0      0.0      0.0    0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaryDummies.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$100,000</th>\n",
       "      <th>$105,000</th>\n",
       "      <th>$110,000</th>\n",
       "      <th>$120,000</th>\n",
       "      <th>$45,000</th>\n",
       "      <th>$50,000</th>\n",
       "      <th>$55,000</th>\n",
       "      <th>$65,000</th>\n",
       "      <th>$70,000</th>\n",
       "      <th>$80,000</th>\n",
       "      <th>$85,000</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.145602</td>\n",
       "      <td>0.006067</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>0.037917</td>\n",
       "      <td>0.037412</td>\n",
       "      <td>0.037412</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.024267</td>\n",
       "      <td>0.151668</td>\n",
       "      <td>0.015167</td>\n",
       "      <td>0.115268</td>\n",
       "      <td>0.235086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.352796</td>\n",
       "      <td>0.077672</td>\n",
       "      <td>0.102515</td>\n",
       "      <td>0.191044</td>\n",
       "      <td>0.189816</td>\n",
       "      <td>0.189816</td>\n",
       "      <td>0.387189</td>\n",
       "      <td>0.153916</td>\n",
       "      <td>0.358790</td>\n",
       "      <td>0.122247</td>\n",
       "      <td>0.319426</td>\n",
       "      <td>0.424160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          $100,000     $105,000     $110,000     $120,000      $45,000  \\\n",
       "count  1978.000000  1978.000000  1978.000000  1978.000000  1978.000000   \n",
       "mean      0.145602     0.006067     0.010617     0.037917     0.037412   \n",
       "std       0.352796     0.077672     0.102515     0.191044     0.189816   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           $50,000      $55,000      $65,000      $70,000      $80,000  \\\n",
       "count  1978.000000  1978.000000  1978.000000  1978.000000  1978.000000   \n",
       "mean      0.037412     0.183519     0.024267     0.151668     0.015167   \n",
       "std       0.189816     0.387189     0.153916     0.358790     0.122247   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           $85,000        price  \n",
       "count  1978.000000  1978.000000  \n",
       "mean      0.115268     0.235086  \n",
       "std       0.319426     0.424160  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       0.000000     0.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaryDummies.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names=['$100,000','$105,000','$110,000','$120,000',\n",
    "                       '$45,000','$50,000','$55,000','$65,000','$70,000',\n",
    "                       '$80,000','$85,000','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'$100,000', u'$105,000', u'$110,000', u'$120,000', u'$45,000',\n",
       "       u'$50,000', u'$55,000', u'$65,000', u'$70,000', u'$80,000', u'$85,000',\n",
       "       u'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaryDummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryDummiesPD=pd.DataFrame(salaryDummies, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'$100,000', u'$105,000', u'$110,000', u'$120,000', u'$45,000',\n",
       "       u'$50,000', u'$55,000', u'$65,000', u'$70,000', u'$80,000', u'$85,000',\n",
       "       u'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaryDummiesPD.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate a non-NDFrame object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-8014d5de2eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearchListingsFinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msearchListings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msalaryDummiesPD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#searchListingsFinal=pd.DataFrame(searchListings).join(pd.DataFrame(salaryDummies))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    843\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot concatenate a non-NDFrame object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate a non-NDFrame object"
     ]
    }
   ],
   "source": [
    "searchListingsFinal=pd.concat([searchListings, salaryDummiesPD],axis =1)\n",
    "#searchListingsFinal=pd.DataFrame(searchListings).join(pd.DataFrame(salaryDummies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-4f9dfedb49d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearchListings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dtype' is not defined"
     ]
    }
   ],
   "source": [
    "dtype(searchListings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
